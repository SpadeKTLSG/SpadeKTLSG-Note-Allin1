--关系型数据库管理系统

‍

‍

开源的关系型数据库管理系统, 由于性能高、成本低、可靠性好，成为最流行的开源数据库

‍

‍

## Header

‍

### 快速

‍

#### JDBC连接格式(本地)

```java
jdbc:mysql://localhost:3306/
```

‍

#### JDBC连接格式(远程)

```java
jdbc:mysql://XXX:3306/
```

‍

#### SQL表测试用

**简介：准备数据库表相关的**

```sql
CREATE TABLE `user` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `phone` varchar(32) DEFAULT NULL,
  `pwd` varchar(128) DEFAULT NULL,
  `sex` int(2) DEFAULT NULL,
  `img` varchar(128) DEFAULT NULL,
  `create_time` datetime DEFAULT NULL,
  `role` int(11) DEFAULT NULL COMMENT '1是普通用户，2是管理员',
  `username` varchar(128) DEFAULT NULL,
  `wechat` varchar(128) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;


INSERT INTO `user` (`id`, `phone`, `pwd`, `sex`, `img`, `create_time`, `role`, `username`,`wechat`)
VALUES
    (1,'123','666',1,'xdclass.net','2021-09-09 00:00:00',1,'jack','xdclass6'),
    (2,'2323432','794666918',1,'wwwww','2020-05-20 04:54:01',1,'SK','xdclass-anna'),
    (3,'2323432','xdclass-lw',1,'wwwww','2020-05-20 04:54:42',1,'二当家小D','xdclass1'),
    (4,'2323432','3232323',1,'wwwww','2020-05-20 04:55:07',1,'老王','xdclass-lw');
```

‍

‍

### 环境

‍

#### Linux配置

见Linux笔记本

‍

#### Win配置

‍

##### 启动

安装工具安装[官网链接](https://dev.mysql.com/downloads/installer/)

记得去任务管理器开启服务

‍

##### 连接

本人固定账号密码: root 2333

‍

###### ==连接MySQL服务器==

‍

**本地连接**

```sql
mysql -u 用户名 -p 密码 [-h数据库服务器的IP地址 -P端口号]
```

> -h 参数不加，默认连接的是本地 127.0.0.1 的MySQL服务器
>
> -P 参数不加，默认连接的端口号是 3306

密码在-p回车之后，在命令行中输入密码，然后回车(安全隐藏密码)

‍

**远程连接**

虚拟机云服务器

‍

‍

###### ==访问Navicat==

直接设置连接, 类似IDEA

‍

###### ==IDEA访问==

直接添加数据源输入账号密码即可

‍

‍

‍

‍

# 知识

‍

## 概念

‍

### 基本概念

‍

#### **数据库**

DataBase 存储数据的仓库，本质是一个文件系统，数据按照特定的格式将数据存储起来，用户可以对数据库中的数据进行增删改查操作

‍

#### **SQL**

SQL（**S**tructured **Q**uery **L**anguage  SQL）    结构化查询语言，操作关系型数据库的编程语言

‍

#### **数据库管理系统**

DataBase Management System，DBMS 操作和管理数据库的大型软件，用于建立、使用和维护数据库，对数据库进行统一管理和控制，以保证数据库的安全性和完整性. 用户通过数据库管理系统访问数据库中表内的数据

‍

‍

#### **结构化查询语言**

Structured Query Language, SQL 数据库查询和程序设计语言，用于存取数据以及查询、更新和管理关系数据库系统

‍

#### 数据库驱动

不同数据库开发商(比如oracle mysql等)为了某一种开发语言能够实现统一的数据库调用而开发的一个程序, 作用相当于一个翻译人员, 将某个语言（比如java）中对数据库的调用通过这个翻译成各个种类的数据库 自己的数据库语言

‍

‍

### 四大连接参数

MySQL驱动类    driver-class-name

登录名    username

密码    password

数据库连接字符串    url

‍

‍

### 常见数据库

* **MYSQL**  开源免费的数据库
* Oracle  收费的大型数据库
* DB2  IBM公司的收费数据库产品,常应用在银行系统中.
* SQLServer  MicroSoft 公司收费的中型的数据库. C#、.net等语言常使用
* SQLite  嵌入式的小型数据库，应用在手机端

‍

‍

### 编程语言概念对应

‍

|Java|SQL|
| :--------: | :--------: |
|类|表|
|类中属性|表中字段|
|对象|记录|

‍

‍

### 设计流程

1. 收集信息, 确认需求
2. 标识实体
3. 标识实体之间关系

‍

#### 类型

‍

##### Innodb

‍

‍

##### myisam

‍

‍

#### 区别

|区别项|Innodb|myisam|
| ----------| -----------------------------------------| --------------------------|
|事务|支持|不支持|
|锁粒度|行锁，适合高并发|表锁，不适合高并发|
|是否默认|默认|非默认|
|支持外键|支持外键|不支持|
|适合场景|读写均衡,写大于读场景，需要事务|读多写少场景，不需要事务|
|全文索引|可以通过插件实现, 更多使用ElasticSearch|支持全文索引|

重点：MyISAM不支持事务，如果需要事务则改为innodb引擎 更改数据库的表里面的引擎

‍

#### 自增

InnoDB自增列会重1开始(存在内存当中的，断电即失)

MylSAM继续从上一个自增量开始(存在文件中的，不会丢失)

‍

## 类型

‍

### 数据库类型

‍

#### **关系型**

MySQL、Oracle、DB2、SQLServer

建立在关系模型基础上，由多张相互连接的**二维表**组成的数据库. 而所谓二维表，指的是由行和列组成的表

‍

* 使用表存储数据，格式统一，便于维护
* 使用SQL语言操作，标准统一，使用方便，可用于复杂查询

‍

‍

#### **非关系型**

Redis

对象存储,通过对象自身的属性来决定

‍

‍

### SQL语言类型

‍

‍

|**分类**|**全称**|**说明**|
| -----| ----------------------------| ---------------------------------------------------------------------------------|
|DDL|Data Definition Language|数据定义语言，定义数据库对象: 数据库，表，列等    关键字：create，alter，drop等|
|DML|Data Manipulation Language|数据操作语言，对数据库表中的数据进行增删改    关键字：insert，delete，update等|
|DQL|Data Query Language|数据查询语言，查询数据库中表的记录    关键字：select，from，where等|
|DCL|Data Control Language|数据控制语言，创建数据库用户、控制数据库访权|

‍

‍

‍

‍

# 基础

‍

‍

## 语句

‍

### 语法

‍

SQL语句可以单行或多行书写，以分号结尾(可使用空格和缩进来增强语句的可读性)

‍

#### 注释

单行注释：-- 注释内容 或 # 注释内容(MySQL特有)

多行注释： /* 注释内容 */

‍

‍

#### 特殊标记

‍

特殊符号或者是内置的名称需要使用 <kbd>``</kbd>​​ 两个波浪符号保证兼容(建议字段和表名都采用)

通配符: *

‍

‍

#### 字段别名

表名/字段名 as 别名    对表和字段名进行重命名别名, **不会修改**底层数据表的字段

许多地方允许直接在字段后面直接跟上别名, 不需要加AS关键字

‍

‍

#### 多元判断

```java
if(表达式, tvalue, fvalue)
```

当表达式为true时，取值tvalue；当表达式为false时，取值fvalue

‍

```java
case 表达式 when 值1 then 结果1 [when 值2 then 结果2 ...] [else result] end
```

‍

‍

### 库DB

‍

#### **增 Create**

创建新数据库    create DATABASE 库名 [CHARACTER SET= ]

‍

#### **删 Drop**

删除数据库    drop database XXX

‍

#### **改 Use**

切换当前数据库    use XXX

切换编码    ALTER DATABASE 名字 CHARACTER SET = 编码

‍

#### **查 Show**

查看所有数据库    show databases

查看某数据库的定义信息    show create database 名字

查看正在使用的数据库    select database()

‍

‍

### 表Table

‍

#### 增 **Create**

‍

##### 添加表

‍

```sql
create table 表名(字段名 类型(长度) 约束,索引,注释)[备注]
```

‍

* 在表的最后可以指定Engine=innodb 以及default charset=utf8等属性

‍

示例

```sql
create table tb_user (
    id int comment 'ID,唯一标识',
    username varchar(20) comment '用户名',
    name varchar(10) comment '姓名',
    age int comment '年龄',
    gender char(1) comment '性别'
) comment '用户表';
```

‍

##### 添加列

‍

```sql
alter table 表名 
add index 索引名字(目标) 列名 类型(长度) 约束 [after 某个字段]
```

‍

* 添加多个字段分类: <kbd>,</kbd>​分隔add之间 / add( 类型(长度) 约束 , ...)
* 需要添加多列，而有一列字段已经添加过了，结果会报错并且全部添加失败

‍

‍

#### **删 Drop**

‍

##### 删除表

‍

‍

==DROP==

drop table 表名

‍

* 完全删除表，数据库就查不到这个表了(可以加IF exist)

‍

‍

==DELETE==

delete from 表名

‍

* 在事务机制下删除，先把要删除的记录保存到日志再删, 保留表的结构，数据库中该表还存在
* 加where条件，可以选定范围
* 下次插入id不会从1开始，而是从最后一次插入的id+1开始

‍

‍

==TRUNCATE==

truncate TABLE 表名

‍

* 在事务机制外删除，速度远超过DELETE语句
* 只能删除全表数据，会保留表结构，数据库中该表还存在
* 下次插入id重新从1开始

‍

‍

##### 删除列

‍

alter table 表名  drop 列名

‍

‍

#### **查 Show**

‍

##### 查看所有表

show tables

‍

##### 查看表结构

desc 表名

show columns from 表名

‍

##### 查看创建语句

查看创建数据库的语句

```sql
show create database 库名
```

查看创建表的语句

```sql
show create table 表名
```

‍

‍

查看建表初期字段忘记写了注释信息的漏网之字段

```sql
show full columns from 表名 where comment = '';
```

‍

#### **改Alter**

‍

==改列==

‍

##### 列Modify

修改列的类型长度及约束

```sql
alter table 表名 modify 列名 类型(长度) 约束
```

‍

‍

##### 列Change

修改列名

```sql
alter table 表名 change 旧列名 新列名 类型(长度) 约束
```

‍

* change和modify都可以修改表的定义，不同的是change后面需要写两次列名，不太方便，但是change的优点是可以修改列名称，modify则不行

‍

‍

##### 列Drop

删除列名

```sql
alter table 表名 drop 字段名
```

‍

‍

==改表==

‍

‍

##### 表**character**

修改表的字符集

```sql
alter table 表名 character set 字符集
```

‍

‍

##### 表Rename

修改表名

```sql
rename table 表名 to 新表名
```

‍

‍

### 字段Field

‍

‍

#### 增 Insert

‍

‍

```sql
Insert [Ignore] into 表名 [字段1,...] values (值1,...), (值1,...);
```

‍

==MySQL方言==

```sql
INSERT INTO 表名 SET 字段1=值1, 字段2=值2...... ;
```

‍

‍

* 插入数据时，指定的字段顺序需要与值的顺序是一一对应的
* 字符串和日期型数据应该包含在引号中
* 不填写字段名就是向全部字段添加数据, 会一一匹配
* IGNORE关键字

  表示**只会插入数据库不存在的记录**

  > 比如主键冲突、唯一性冲突，数据库会报错，加上IGNORE之后数据库会忽略这条数据不会报错
  >
* 不写字段列表也可以插入数据，但是会影响速度

  > Mysql会进行词法分析，找到对应表结构，然后自动给你补上字段列表
  >

‍

‍

‍

##### 主键冲突

确实非得添加这个记录, 可以选择性的进行处理: 更新和替换

‍

**更新**

```sql
Insert into 表名[(字段列表:包含主键)] values(值列表) on duplicate key update 字段 = values(字段);
```

‍

**替换**

```sql
Replace into 表名 [(字段列表:包含主键)] values(值列表);
```

‍

‍

##### 快速复制

从已有的数据中去获取数据,然后将数据又进行新增操作

> 从已有表拷贝数据到新表中,可以迅速的让表中的数据膨胀到一定的数量级, 通常用来测试表的压力以及效率

‍

**从已有表创建新表(复制表结构)**

‍

```sql
Create table 表名 like 数据库.表名;
```

‍

‍

**蠕虫复制**

先查出数据, 然后新增

‍

```sql
Insert into 表名[(字段列表)] select 字段列表/* from 数据表名;
```

‍

‍

#### 删 Delete

‍

```sql
DELETE [IGNORE] FROM 表名 [WHERE 条件1, 条件2, ] [ORDER BY ...] [LIMIT ...];
```

‍

* 如果表中存在主键自增长,那么当删除之后自增长不会还原
* 如果没有条件，则会删除整张表的所有数据
* DELETE 语句不能删除某一个字段的值, 此时可以使用UPDATE，将该字段值置为NULL即可

‍

‍

##### 连接删除

‍

==内连接==

```sql
DELETE 表1, ... FROM 表1 JOIN 表2 ON 条件
```

‍

==外连接==

```sql
DELETE 表1, ... FROM 表1 [LEFT | RIGHT] JOIN 表2 ON 条件
```

‍

‍

#### 改 Update

‍

```sql
UPDATE [IGNORE] 表名 SET 字段1 = 值1,...[WHERE][ORDER BY][LIMIT];
```

‍

‍

##### 连接修改

‍

==内连接==

UPDATE 表1 JOIN 表2     ON 条件(AND)     SET 字段1 = 值1

UPDATE 表1 JOIN 表2     SET 字段1 = 值1    WHERE 条件(AND)

‍

==外连接==

UPDATE 表1 [LEFT | RIGHT]     JOIN 表2 ON 条件  SET 字段1 = 值1

‍

‍

#### 查 Select

‍

##### DQL查询语句的语法结构

```mysql
SELECT
	字段列表
FROM
	表名列表
WHERE
	条件列表
GROUP  BY
	分组字段列表
HAVING
	分组后条件列表
ORDER BY
	排序字段列表
LIMIT
	分页参数
```

```sql
Select [字段]/* from 源 [where] [group by] [having] [order by] [limit]
```

‍

‍

##### 关键字先后顺序

‍

```sql
FROM -> WHERE -> GROUP BY -> SELECT -> ORDER BY -> LIMIT
```

‍

1. table部分  形成表  
    (1) from  
    (2) on  
    (3) join
2. filter部分  过滤条件  
    (4) where  
    (5) group by  
    (6) having + 聚合函数
3. show部分  展示  
    (7) select  
    (8) distinct  
    (9) order by  
    (10) limit

‍

* 条件执行的顺序是从左到右的. 应该把索引条件或者筛选掉记录最多的条件写在最左侧: 索引查询速度快，筛选记录最多的条件更容易触发短路语句的效果

‍

‍

‍

‍

‍

---

‍

##### 条件andnot

‍

|**比较运算符**|**功能**|
| :-------------------: | ----------------------------------------------|
|<> 或 !=|不等于|
|between ... and ...|在某个范围之内 (含最小、最大值)|
|in(...)|在in之后的列表中的值，多选一|
|like 占位符|模糊匹配 (_匹配任意1个字符, %匹配任意个字符)|
|is null|是null|

‍

|**逻辑运算符**|**功能**|
| :---------: | ---------------------------------|
|and 或 &&|并且 (多个条件同时成立)|
|or 或||
|not 或 !|非 , 不是    很方便在取反中使用|

‍

---

##### 聚合MaxMin

‍

```sql
SELECT [聚合(字段)] FROM ......;
```

‍

|**函数**|**功能**|
| :-----: | :--------: |
|count|统计数量|
|max|最大值|
|min|最小值|
|avg|平均值|
|sum|求和<sup>（不是数值类型，那么计算结果为0）</sup>|

‍

* 聚合函数查询就是纵向查询，对一列的值进行计算
* 几乎所有的聚合函数都会忽略空值(null)，除了count(数字)、count(*)
* 统计数量可以使用：count()   count(字段)   count(常量)

  推荐count(*); 一列中有null的行，该行不会被统计

‍

‍

---

##### 筛选Where

```sql
SELECT ... FROM ... WHERE 条件 [AND | OR] 条件 ...;
```

‍

* 可以使用表的别名
* 用来判断数据,筛选数据
* where不能对聚合函数进行判断
* 返回结果 0或者1, 0代表false, 1代表true
* 分组之前进行过滤，不满足where条件，不参与分组   --而having是分组之后对结果进行过滤.
* 判断某个字段是NULL就满足条件，用WHERE comm IS NULL 而不是WHERE comm = NULL

  如果不为空则满足条件，是WHERE comm IS NOT NULL 而不是WHERE comm != NULL

‍

‍

---

##### 分组Groupby

```sql
Group by 字段 [,字段] [With Rollup]
```

‍

* 多列分组条件，执行的时候逐级分组
* 可以使用select中字段的别名（不是表的别名），后面的语句中都可以使用
* 主要用来分组查询, 通过一定的规则将一个数据集划分为若干个小的区域，然后针对每个小区域分别进行数据汇总处理. 分组查询通常会使用聚合函数进行计算
* 分组之后，查询的字段一般为聚合函数和分组字段，查询其他字段无任何意义.
* With Rollup 是 回溯统计,对分组结果集再次做汇总计算, 最下面多一行结果

‍

‍

==组连接==

把分组查询中的某个字段拼接成一个字符串

```sql
Select , , Group_concat from...... 
```

‍

示例

```sql
SELECT deptno, COUNT(*), GROUP_CONCAT(ename)
FROM t_emp
WHERE sal >= 2000
GROUP BY deptno;    #看到ename都是逗号连接的字符串
```

‍

‍

---

##### 聚筛Having

‍

```sql
Having [ conditions ]
```

‍

* Having能做where能做的几乎所有事情, 但是where却不能做having能做的很多事情; 它的出现主要是为了WHERE子句不能使用聚合函数的问题
* HAVING子句不能独立存在，必须依赖于GROUP BY子句而存在，GROUP BY 执行完成就立即执行HAVING子句
* 分组统计的**结果**或者说统计**函数**都只有having能够使用
* Having能够使用字段别名，where不能

  where是从磁盘取数据进行判断，进入到内存之后进行Groupby操作，分组结果之后需要having来处理; 而名字只可能是字段名，别名是在字段进入到内存后才会产生
* **WHERE能完成的就用WHERE完成**，不要放到HAVING中  

  大量的数据从磁盘读取到内容代价比较大，先筛选完了，再把符合条件的记录读取到内存中显然更好
* 执行顺序: Where -> Groupby -> Having

‍

示例

```sql
SELECT deptno, COUNT(*) FROM t_emp
GROUP BY 1  //先分组送进来再删选
HAVING deptno IN(10, 30);/*效率低了*/
 
SELECT deptno, COUNT(*) FROM t_emp 
WHERE deptno IN(10, 30)    //直接先筛选后Groupby
GROUP BY 1;
```

‍

‍

---

##### 去重Distinct

‍

```sql
SELECT DISTINCT [字段] FROM 源;
```

‍

* 只能存在于select子句查询一个字段的情况，否则要么失效，要么语法报错

  只能在select子句中使用一次,只能写在select子句的第一个字段前面

  若有多个字段，则只有多个字段的值都相同的情况才会被认为是重复记录，distinct才会生效

‍

‍

---

##### 排序Orderby

‍

```sql
Order by 字段名1 [,字段名2] [asc|desc];
```

‍

* 支持**单字段和多字段**规定首要条件和次要条件排序, 会先按照首要条件排序再启用次要条件再次排序
* 默认asc升序, desc降序

‍

‍

---

##### 分页Limit

‍

**只用来限制长度(数据量)**

```sql
limit 数据量;
```

‍

**限制起始位置,限制数量**

```sql
limit 起始索引, 查询记录数;
```

‍

‍

限制结果来实现数据的分页,,减少资源的浪费

‍

* 起始索引从0开始.   
  ==起始索引== = （查询页码 - 1）* 每页显示记录数
* 如果查询的是第一页数据，起始索引可以省略，直接简写为 limit 条数
* 第二个参数-1代表查询到末尾

‍

‍

---

##### Select函数

‍

‍

==常用==

```sql
select concat(字段1,字段2) as 新名字 from    将查询的数据连接起来并起别名输出
```

‍

now    当前时间

current_date()    
curdate    获取当前日期

‍

‍

system_user

user    获取当前用户

version    获取版本

‍

‍

##### **==进阶Select==**

可以用Select调用函数,表达式,变量; 并且select 字段后可以跟计算表达式(select 字段+1 from...)

使用.号来访问表的字段列名

‍

---

‍

#### 多表Join

‍

左表 [cross] join 右表, 从一张表中循环取出每一条记录, 每条记录都去另外一张表的所有记录逐个进行匹配，并保留所有记录. 这种结果称为笛卡尔积(交叉连接), 需要消除无效的笛卡尔积只保留表关联部分的数据

‍

##### 交叉连接

没用

‍

‍

##### 内连接

查询两表或多表中交集部分数据, 语法上分为隐显

‍

==显式==

```sql
SELECT ... FROM 表1  [INNER] JOIN 表2 ON 条件...
```

‍

==隐式==

```sql
SELECT ... FROM 表1 JOIN 表2 ON 连接条件;
SELECT ... FROM 表1 JOIN 表2 WHERE 连接条件;
SELECT ... FROM 表1, 表2 WHERE 连接条件;
```

‍

* 不同表有同名字段就需要别名(AS)

‍

##### 外连接

**左(外)连接和右(外)连接**

‍

```sql
SELECT ... from 左表 left/right [outer] join 右表 on 连接条件;
```

‍

‍

* 左连接就是以左为主, 保留左表所有记录与右表做连接<sup>（另一种说法: 左外连接相当于查询表1(左表)的所有数据，当然也包含表1和表2交集部分的数据）</sup>. 右表有符合条件的记录就与左表连接,没有就NULL
* 右连接亦然. 开发使用时更偏向于左外连接
* 外连接与内连接的区别在于，除了符合条件的记录之外，结果集中还会保留主表不符合条件的记录; 写在WHERE子句里的条件，不符合条件的记录被过滤掉
* 左外连接和右外连接是可以相互替换的，只需要调整连接查询时SQL语句中表的先后顺序就可以了

‍

‍

##### 自然连接

自动匹配连接条件, 系统以字段名字作为匹配模式(同名字段就作为条件, 多个同名字段都作为条件)

可以分为自然内连接和自然外连接

‍

**自然内连接**

```sql
左表 natural join 右表
```

‍

**自然外连接**

```sql
左表 natural left/right join 右表
```

‍

> 内连接和外连接都可以模拟自然连接: 使用同名字段,合并字段
>
> 左表 left/right/inner join 右表 using(字段名);  -- 使用同名字段作为连接条件: 自动合并条件

‍

‍

#### 子查询( )

sub query

嵌套查询: 查询是在某个查询结果之上进行的

使用()括子语句

‍

==根据结果的不同分类==

1. 标量子查询  （子查询结果为单个值[一行一列]）常用的操作符： = <> > >= < <=
2. 列子查询  （子查询结果为一列，但可以是多行）常用的操作符: IN, NOT IN
3. 行子查询  （子查询结果为一行，但可以是多列）常用的操作符：= 、<> 、IN 、NOT IN
4. 表子查询  （子查询结果为多行多列[相当于子查询结果是一张表]）常作为临时表

‍

‍

==书写位置==

‍

~~Where子查询~~  
子查询出现where条件中，where语句里**不推荐**使用子查询，每执行一次where条件筛选，就会进行一次子查询，效率低下. 这种反复子查询就属于**相关子查询**

‍

~~SELECT子查询~~  
子查询跟在SELECT之后，SELECT子查询也是相关子查询，**不推荐**

‍

==From子查询==

子查询跟在from之后，通常这种子查询的结果集作为一个临时表，from子查询只会执行一次，不是相关子查询，所以==查询效率高==. 

‍

‍

##### WHERE子句

Where子句中，可以用IN、ALL、ANY、EXISTS关键字来处理多行表达式结果集的条件判断

```sql
SELECT ename FROM t_emp
WHERE sal > ALL
(SELECT sal FROM t_emp
WHERE ename IN("FORD","MARTIN"));
```

‍

‍

##### EXISTS

Exists把原来在子查询之外的条件判断，写到了子查询的里面. 

```sql
SELECT ... FROM 表名 WHERE [NOT] EXISTS (子查询)
```

‍

‍

## 结构属性

‍

### 表Table

‍

所有的关系都是指的表与表之间的关系, 将实体与实体的关系, 反应到最终数据库表的设计上来

‍

#### 表关系

‍

##### 一对一

一张表的一条记录一定只能与另外一张表的一条记录进行对应  
通常是用来做单表的拆分

‍

==实现==

任意一方加入外键，关联另外一方的主键，并且设置外键唯一

‍

‍

##### 一对多

一张表中有一条记录可以对应另外一张表中的多条记录  
另外一张表的一条记录只能对应第一张表的一条记录

‍

==实现==

多的一方，添加字段，来关联属于一这方的主键

‍

‍

##### 多对多

一张表中(A)的一条记录能够对应另外一张表(B)中的多条记录  
同时B表中的一条记录也能对应A表中的多条记录

‍

==实现==

建立中间表维护双方索引

‍

‍

### 字段Field

‍

#### 约束

作用在表中字段上的规则，用于限制存储在表中的数据

‍

|**约束**|**描述**|**关键字**|
| :--------: | --------------------------------------------------| -------------|
|非空约束|限制该字段值不能为null|not null|
|唯一约束|保证字段的所有数据都是唯一、不重复的|unique|
|主键约束|主键是一行数据的唯一标识，要求非空且唯一|primary key|
|*默认约束*|保存数据时，如果未指定该字段值，则采用默认值|*default*|
|外键约束|让两张表的数据建立连接，保证数据的一致性和完整性|foreign key|

‍

‍

##### 非空约束

NOT NULL! 

‍

‍

##### 唯一约束

数据不能重复

唯一键与主键本质相同, 区别就是唯一键**默认允许为空,而且是多个为空**

‍

**==设定==**

‍

**创建表时**

字段之后直接跟 unique key

‍

复合唯一键

所有的字段之后增加unique key(字段列表);

‍

**创建表之后**

‍

先删除后新增

Alter table 表名 drop index 索引名字;  
Alter table 表名  add unique key(字段列表);  
修改属性

‍

> 唯一键默认的使用字段名作为索引名字

‍

‍

##### 主键约束

‍

原理其实就是一个计数器

一张表只能有最多一个主键, **尽量使用整数类型而不是字符串类型, 因为数字的检索速度非常快,并且还可以设置自动增长**

在实际创建表的过程中, 很少使用真实业务数据作为主键字段; 大部分的时候是使用逻辑性的字段

‍

**==设定==**

‍

**创建表时**

字段之后    primary key     (单个字段作为主键)

所有的字段之后    primary key     (主键字段列表, 如果有多个字段作为主键,可以是复合主键)

‍

**创建表之后**

Alter table 表名  drop primary key;  
Alter table 表名  add primary key(字段列表);

‍

‍

‍

###### **主键自增**

**auto_increment**

‍

当对应的字段,不给值,或者说给默认值/NULL时, 系统会从当前字段中已有的最大值再进行+1操作, 得到一个新的在不同的字段.

如果对应的字段输入了值,那么自增长失效: 但是下一次还是能够正确的自增长(从最大值+1)

**自增长的字段必须定义为主键，字段必须是数字(整型),**  **默认起始值是1而不是0 (正数序列开始增长)**

‍

==设定==

‍

必须先删除自增长,后增加(一张表只能有一个自增长)

‍

修改当前自增长已经存在的值

> 修改只能比当前已有的自增长的最大值大, 不能小(小不生效)

```sql
Alter table 表名 auto_increment  = 值;
```

‍

‍

通过modify来进行修改

> 保证字段没有auto_increment即可

```sql
Alter table 表名 modify 字段 类型;
```

‍

‍

示例

```sql
create table tb_user (
    id int primary key auto_increment comment 'ID,唯一标识', #主键自动增长
    username varchar(20) not null unique comment '用户名',
    name varchar(10) not null comment '姓名',
    age int comment '年龄',
    gender char(1) default '男' comment '性别'
) comment '用户表';
```

‍

‍

##### 外键约束

==不推荐使用==

‍

**物理外键**定义

使用foreign key定义外键关联另外一张表. 如果一张表中有一个字段(非主键)指向另外一张表的主键,那么将该字段称之为外键

默认作用

对父表    父表数据操作, 如果**对应的主键在子表中已经被数据所引用**, 那么就不允许操作

对子表(外键字段所在的表)   子表数据操作时, 如果对应的外键字段在父表**找不到对应的匹配,**  操作会失败

‍

==起效条件==

一张表可以有名字不相同的多个外键, 外键字段的字段类型(列类型)必须与父表的主键类型完全一致, 一张表中的外键名字不能重复, 增加外键的字段(数据已经存在),必须保证数据与父表主键要求对应

‍

**问题**

‍

* 影响增、删、改的效率（需要检查外键关系
* 仅用于单节点数据库，不适用与分布式、集群场景
* 容易引发数据库的死锁问题<sup>（处理过程中形成外键闭环，我们将无法删除任何一张表的数据记录）</sup>，消耗性能.

> 在现在的企业开发中，很少会使用物理外键，都是使用逻辑外键
>
> 甚至在一些数据库开发规范中，会明确指出禁止使用物理外键 foreign key
>
> 通常在业务层逻辑中，解决外键关联

‍

‍

‍

**==设定==**

‍

**创建表时增加**

在最后创建Key 名称 之后(), 然后使用

```sql
[constraint] [外键名称] foreign key(外键字段) references 主表 (主表列名)
```

‍

**新增表之后增加**

```sql
Alter table 表名 add constraint 外键名字 foreign key(外键字段) references 父表(主键字段);
```

‍

**只能先删除后新增**

```sql
Alter table 表名 drop foreign key 外键名;
```

‍

‍

‍

### 值Value

‍

#### Tips

‍

#### 数值类型

‍

|类型|大小|有符号(SIGNED)范围|无符号(UNSIGNED)范围|描述|
| -------------| --------| -------------------------------------------------------| -----------------------------------------------------------| --------------------|
|TINYINT|1byte|(-128，127)|(0，255)|小整数值|
|SMALLINT|2bytes|(-32768，32767)|(0，65535)|大整数值|
|MEDIUMINT|3bytes|(-8388608，8388607)|(0，16777215)|大整数值|
|INT/INTEGER|4bytes|(-2147483648，2147483647)|(0，4294967295)|大整数值|
|BIGINT|8bytes|(-2<sup>63，2</sup>63-1)|(0，2^64-1)|极大整数值|
|FLOAT|4bytes|(-3.402823466 E+38，3.402823466351 E+38)|0 和 (1.175494351 E-38，3.402823466 E+38)|单精度浮点数值|
|DOUBLE|8bytes|(-1.7976931348623157 E+308，1.7976931348623157 E+308)|0 和 (2.2250738585072014 E-308，1.7976931348623157 E+308)|双精度浮点数值|
|DECIMAL||依赖于M(精度)和D(标度)的值|依赖于M(精度)和D(标度)的值|小数值(精确定点数)|

‍

==常用数据类型==

int 整型    double 浮点型    varchar 字符串型    date 日期型

‍

**注意**

1. BOOLEAN在数据库保存的是tinyInt类型，false为0，true就是1
2. **char是定长，varchar是变长**

    char存储时，如果字符数没有达到定义的位数，后面会用空格填充到指定长度，而varchar没达到定义位数则不会填充，按实际长度存储

    char长度固定，char存取速度还是要比varchar要快得多；但是char也为此付出的是空间的代价. varchar则刚好相反
3. Decimal是用来解决小数不精确问题的类型,底层用字符串解析小数
4. 需要声明无符号时候,直接空格后跟unsigned即可

‍

‍

#### **字符串类型**

‍

|类型|大小|描述|
| ------------| -----------------------| -----------------------------------------|
|CHAR|0-255 bytes|定长字符串(需要指定长度),性能高浪费空间|
|VARCHAR|0-65535 bytes|变长字符串(需要指定长度),性能低节省空间|
|TINYBLOB|0-255 bytes|不超过255个字符的二进制数据|
|TINYTEXT|0-255 bytes|短文本字符串|
|BLOB|0-65 535 bytes|二进制形式的长文本数据|
|TEXT|0-65 535 bytes|长文本数据|
|MEDIUMBLOB|0-16 777 215 bytes|二进制形式的中等长度文本数据|
|MEDIUMTEXT|0-16 777 215 bytes|中等长度文本数据|
|LONGBLOB|0-4 294 967 295 bytes|二进制形式的极大文本数据|
|LONGTEXT|0-4 294 967 295 bytes|极大文本数据|

‍

##### **varchar**

‍

###### **长度选择**

‍

varchar字段长度 = 字符串长度值 + 实际数据长度 N. 

‍

字符串长度值视实际数据长度，需占用 1 或 2 个字节存储. 所以：

* 当实际数据长度  **≤**  255 时，varchar字段长度 = 1 + N
* 当实际数据长度  **&gt;**  255 时，varchar字段长度 = 2 + N

varchar主要根据字段实际使用的长度来分配存储空间

在内存中的操作方式，varchar也是按照最长的方式在内存中进行操作的. 比如说要进行排序的时候，varcahr(100)是按照100这个长度来进行的，不合理的长度会浪费内存空间. 

‍

**0&lt;N≤64**

根据实际数据长度N，选择一个相近的 2^n**2**n 长度

* ​`varchar(8)`​, `varchar(16)`​, `varchar(32)`​, `varchar(64)`​

‍

> 例
>
> 1. 手机号11位，可以选择varchar(16)
>
> 原因：
>
> * ​`1 bytes = 8 bit`​ ，一个字节最多可以代表的数据长度是2的8次方 `11111111`​ 在计算机中也就是-128到127.
> * 使用 2^n**2**n 长度是更好的磁盘或内存块对齐.
> * 对齐块更快. 今天“块”的大小更大，内存和磁盘足够快，可以忽略对齐，对于非常大的块来说是非常重要的.

‍

**N**>**64**

根据实际数据长度N，选择一个相近的 2^{n-1}**2**n **−** 1 长度

* ​`varchar(127)`​, `varchar(255)`​, `varchar(511)`​, ...

> 例
>
> 1. 收货地址接近100个字符，可以选择varchar(127)
> 2. 商品名称，接近256个字符，可以选择varchar(255)
>
> 原因：
>
> 1. 方便InnoDB建索引，对于 MyISAM，可以对前 1000 个字节做索引，对于 InnoDB，则只有 767 字节. （来源依据）. 255X3=765
> 2. 少申请一个字节，记录字符串长度，一个8位的tinyint，可以表示的无符号数值的范围是，0-255，如果长度超过了255，需要在申请个字节.
> 3. 磁盘块和内存块对齐

‍

‍

‍

‍

‍

‍

#### **时间类型**

|类型|大小|范围|格式|描述|
| -----------| ------| --------------------------------------------| ---------------------| --------------------------|
|==DATE==|3|1000-01-01 至 9999-12-31|YYYY-MM-DD|日期值|
|TIME|3|-838:59:59 至 838:59:59|HH:MM:SS|时间值或持续时间|
|YEAR|1|1901 至 2155|YYYY|年份值|
|==DATETIME==|8|1000-01-01 00:00:00 至 9999-12-31 23:59:59|YYYY-MM-DD HH:MM:SS|混合日期和时间值|
|TIMESTAMP|4|1970-01-01 00:00:01 至 2038-01-19 03:14:07|YYYY-MM-DD HH:MM:SS|混合日期和时间值，时间戳|

‍

‍

‍

‍

‍

‍

## 用户权限

‍

‍

创建用户  

```sql
CREATE USER 用户名 IDENTIFIED BY '密码'
```

‍

删除用户

```sql
DROP USER 用户
```

‍

修改密码(修改当前用户密码)  

```sql
SET PASSWORD = PASSWORD ('123456')
```

修改密码(修改指定用户密码)  

```sql
SET PASSWORD FOR kuangshen = PASSWORD ( '123456')
```

‍

重命名  

```sql
RENAMFUSER 原来名字 To 新的名字
```

‍

用户授权

```sql
GRANT ALLPRIVILEGES ON *.* To 用户
```

‍

查询权限

```sql
Show GRANTS FOR 用户
```

‍

给予Roor用户权限

```sql
GRANT ALL PRIVILEGES ON. To 'root' @ 'localhost' WITH GRANT OPTION
```

‍

撤销权限 REVOKE 哪些权限，在哪个库撤销，给谁撤销  

```sql
REVOKE ALL PRIVILEGES ON *.* FROM 用户
```

​​

## 索引

某个表中一列或者若干列值的集合和相应的指向表中物理标识这些值的数据页的逻辑指针List

系统根据某种算法, 将已有的数据(未来可能新增的数据), 单独建立一个索引文件, 它能够实现快速的匹配数据, 并且能够快速的找到对应表中的记录,提升查询数据的效率,约束数据的有效性(唯一性等)的帮助数据库高效获取数据的数据结构, 使用索引可以提高查询的效率

平常所说的索引，指默认的 B+Tree 结构组织的索引

MySQL数据库支持的索引结构：Hash索引、B+Tree索引、Full-Text索引等

索引一般建立在用来查询字段之上. 数据量很大，且经常被查询的数据表可以设置索引(即读多写少的表可以设置索引)

* 不要在大字段上创建索引(查找排序时间变的很长)
* 不要对进程变动的数据加索引

‍

==优点==

* 提高数据查询的效率，降低数据库的IO成本.
* 通过索引列对数据进行排序，降低数据排序的成本，降低CPU消耗.

‍

‍

==缺点==

* 索引会**占用存储空间**.
* 索引**提高了查询效率**，同时却也**降低了插入, 更新, 删除的效率**.

‍

‍

### 类型

‍

功能分类

* 主键索引：一种特殊的唯一索引，不允许有空值，一般在建表时同时创建主键索引
* 单列索引：一个索引只包含单个列，一个表可以有多个单列索引（普通索引）
* 联合索引：顾名思义，就是将单列索引进行组合
* 唯一索引：索引列的值必须唯一，**允许有空值**，如果是联合索引，则列值组合必须唯一

  * NULL 值可以出现多次，因为两个 NULL 比较的结果既不相等，也不不等，结果仍然是未知
  * 可以声明不允许存储 NULL 值的非空唯一索引
* 外键索引：只有 InnoDB 引擎支持外键索引，用来保证数据的一致性、完整性和实现级联操作

‍

结构分类

* BTree 索引：MySQL 使用最频繁的一个索引数据结构，是 InnoDB 和 MyISAM 存储引擎默认的索引类型，底层基于 B+Tree
* Hash 索引：MySQL中 Memory 存储引擎默认支持的索引类型
* R-tree 索引（空间索引）：空间索引是 MyISAM 引擎的一个特殊索引类型，主要用于地理空间数据类型
* Full-text 索引（全文索引）：快速匹配全部文档的方式。MyISAM 支持， InnoDB 不支持 FULLTEXT 类型的索引，但是 InnoDB 可以使用 sphinx 插件支持全文索引，MEMORY 引擎不支持

‍

|索引|InnoDB|MyISAM|Memory|
| -----------| ------------------| --------| --------|
|BTREE|支持|支持|支持|
|HASH|不支持|不支持|支持|
|R-tree|不支持|支持|不支持|
|Full-text|5.6 版本之后支持|支持|不支持|

‍

‍

#### 功能分类

‍

##### 单值索引

> 表结构：（age,name,addr）

以单列为索引。以age为单值索引

一个表可以有多个单值索引，age可以，name也可以

```sql
create index name_index on user(name)
```

##### 唯一索引

唯一索引不能重复。

比方说age就不能当作唯一索引，因为很多人都可能使18岁

```sql
create unique index name_index user(name)
```

==一般使用id作为单值索引==

‍

##### 复合索引(联合索引)

由多个列构成的索引，相当于书的二级目录

```sql
create index name_age_index on user(name,age)
```

​`(name,age)`​:先通过name查询，name一样再通过age查询

复合索引的列不一定都能用到（==最左前缀原则==）

如User表的name和city加联合索引就是(name,city)。而==最左前缀原则==指的是，**如果查询的时候查询条件精确匹配索引的左边连续一列或几列，则此列就可以被用到**。如下：

```sql
select * from user where name=xx and city=xx ; //可以命中索引
select * from user where name=xx ; // 可以命中索引
select * from user where city=xx ; // 无法命中索引        
```

* 第一句SQL：

  * 如果查询出多个name，则再去查询city
  * 如果查询出一个name，那就没有必要再去查询city了
* 第二句SQL：因为只查询name，所以city就不用再去查询了

> 需要注意的是，查询的时候如果两个条件都用上了，但是顺序不同，如 `city= xx and name ＝xx`​，那么现在的查询引擎会自动优化为匹配联合索引的顺序，这样是能够命中索引的。
>
> 由于最左前缀原则，在创建联合索引时，索引字段的顺序需要考虑字段值去重之后的个数，较多的放前面。ORDER BY子句也遵循此规则。

‍

##### 避免冗余索引

冗余索引指的是索引的功能相同，能够命中就肯定能命中 ，那么就是冗余索引。如`(name,city)`​和`(name)`​这两个索引就是冗余索引

* 能够命中后者的查询肯定是能够命中前者的
* 在大多数情况下，都应该尽量扩展已有的索引而不是创建新索引。

MySQL 5.7 版本后，可以通过查询 sys 库的 `schema_redundant_indexes`​ 表来查看冗余索引

‍

‍

##### 为字段添加索引

1. 添加Primary key（主键索引）

    ```sql
    alter table `table_name` add PRIMARY KEY (`column`)
    ```
2. 添加unique（唯一索引）

    ```sql
    alter table `table_name` add UNIQUE (`column`)
    ```
3. 添加Index（普通索引）

    ```sql
    alter table `table_name` add index index_name (`column`)
    ```
4. 添加FullText（全文索引）

    ```sql
    alter table `table_name` add FULLTEXT (`column`)
    ```
5. 添加多列索引

    ```sql
    alter table `table_name` add index index_name (`column`,`column`,`column`)
    ```

‍

#### 结构分类

‍

##### 二叉树索引

每一个节点保存的是key-value数据

* key：索引值
* value：该数据的存放地址

> 比如：col2为索引字段
>
> ​`select * from user where Col2 = 89`​
>
> * 会先在树中找到索引值89
> * 获取value值（该数据存放地址），然后通过地址拿取数据

当索引值为自增时，二叉树就变成了链表，==所以MySQL数据库不采用这个索引结构==

‍

##### 红黑树索引

> 每次新增数据，都会进行大量的平衡判断，而且数据量特别大的时候，红黑树的深度会很大，再进行搜索时会比较耗时
>
> ==所以MySQL索引结构不采用红黑树==

‍

##### Hash表

通过索引值进行hash散列计算，算出来的值和数据内存地址存放到映射表中

在对数据进行查询时，通过key的散列值查找数据内存地址。所以无法实现范围查询、比较查询等

‍

##### B-树

* 叶节点具有相同的高度，叶节点的指针为空
* 所有索引元素不重复
* 节点中的数据索引从左到右递增排序

‍

##### B+树

> B-Tree的变种

* 非叶子节点不存储data，只存储索引（冗余索引），可以放更多的索引
* 叶子节点包含所有索引字段
* 叶子节点用指针连接，提高区间访问的性能

> 每一个叶子节点默认16384字节（16KB）
>
> 每个索引节点：
>
> * 索引值：8B
> * 指针：6B
>
> 所以，每个叶子节点（16KB）/每个索引节点（14B）= 1170个索引节点。 所以B+数在高度为3的时候，可以存储的索引节点为：1170×1170×16 ≈ 2千万
>
> ==所以索引可以支持千万级别表的快速查找==

‍

‍

‍

‍

### 主键索引和非主键索引

> 例如下表，主键为ID，K为非主键索引

|ID|name|age|K|
| -----| ------| -----| ---|
|100|张一|10|1|
|300|张二|10|2|
|400|张三|10|3|
|600|张四|10|4|

‍

其中R代表一整行数据

从图中不难发现，主键索引和非主键索引的区别是：

* 非主键索引的叶子节点存放的是==主键值==
* 主键索引的叶子节点存放的是==整行数据==

> 其中非主键索引也被称为==二级索引==
>
> 主键索引也被称为==聚簇索引==

查询过程：

* ​`select * from user where ID=100`​:主键查询，只需要搜索ID这颗B+树
* ​`select * from user where K=1`​:非主键查询

  * 先搜索K索引树，得到主键值：100
  * 再到ID索引树搜索，得到整行数据

  > 此过程也被称为==回表==
  >

‍

‍

### CRUD

[Link](https://blog.csdn.net/wangfeijiu/article/details/113409719)

‍

#### 创建

‍

**普通索引**

```sql
CREATE INDEX 索引名称 ON 表名(字段);
```

```sql
ALTER TABLE 表名 ADD INDEX 索引名称(字段);
```

‍

‍

**唯一索引**

多个列均可标注,防止列名重复, 本身可以重复

```sql
CREATE UNIQUE INDEX 索引名称 ON 表名(字段)
```

‍

**联合索引**

```sql
CREATE INDEX 索引名称 ON 表名(字段1，字段2...)
```

‍

‍

```sql
-- 创建普通索引 
CREATE INDEX index_name ON table_name(col_name);

-- 创建唯一索引
CREATE UNIQUE INDEX index_name ON table_name(col_name);

-- 创建普通组合索引
CREATE INDEX index_name ON table_name(col_name_1,col_name_2);

-- 创建唯一组合索引
CREATE UNIQUE INDEX index_name ON table_name(col_name_1,col_name_2);

```

‍

修改表结构创建索引

```sql
ALTER TABLE table_name ADD INDEX index_name(col_name);
```

‍

创建表时直接指定索引

```sql
CREATE TABLE table_name (
    ID INT NOT NULL,
    col_name VARCHAR (16) NOT NULL,
    INDEX index_name (col_name)
);
```

‍

#### 删除

```sql
-- 直接删除索引
DROP INDEX index_name ON table_name;

-- 修改表结构删除索引
ALTER TABLE table_name DROP INDEX index_name;

```

‍

#### 其他

```sql
-- 查看表结构
desc table_name;

-- 查看生成表的SQL
show create table table_name;

-- 查看索引信息（包括索引结构等）
show index from  table_name;

-- 查看SQL执行时间（精确到小数点后8位）
set profiling = 1;
SQL...
show profiles;

```

‍

‍

### 作用

‍

* 通过创建唯一索引，可以保证数据记录的唯一性。
* 可以大大加快数据检索速度。
* 可以加速表与表之间的连接，这一点在实现数据的参照完整性方面有特别的意义。
* 在使用ORDER BY和GROUP BY子句中进行检索数据时，可以显著减少查询中分组和排序的时间。
* 使用索引可以在检索数据的过程中使用优化隐藏器，提高系统性能

‍

‍

### 结构

‍

#### 数据页

文件系统的最小单元是块（block），一个块的大小是 4K，系统从磁盘读取数据到内存时是以磁盘块为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么

InnoDB 存储引擎中有页（Page）的概念，页是 MySQL 磁盘管理的最小单位

* **InnoDB 存储引擎中默认每个页的大小为 16KB，索引中一个节点就是一个数据页**，所以会一次性读取 16KB 的数据到内存
* InnoDB 引擎将若干个地址连接磁盘块，以此来达到页的大小 16KB
* 在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘 I/O 次数，提高查询效率

超过 16KB 的一条记录，主键索引页只会存储部分数据和指向**溢出页**的指针，剩余数据都会分散存储在溢出页中

数据页物理结构，从上到下：

* File Header：上一页和下一页的指针、该页的类型（索引页、数据页、日志页等）、**校验和**、LSN（最近一次修改当前页面时的系统 lsn 值，事务持久性部分详解）等信息
* Page Header：记录状态信息
* Infimum + Supremum：当前页的最小记录和最大记录（头尾指针），Infimum 所在分组只有一条记录，Supremum 所在分组可以有 1 ~ 8 条记录，剩余的分组可以有 4 ~ 8 条记录
* User Records：存储数据的记录
* Free Space：尚未使用的存储空间
* Page Directory：分组的目录，可以通过目录快速定位（二分法）数据的分组
* File Trailer：检验和字段，在刷脏过程中，页首和页尾的校验和一致才能说明页面刷新成功，二者不同说明刷新期间发生了错误；LSN 字段，也是用来校验页面的完整性

数据页中包含数据行，数据的存储是基于数据行的，数据行有 next_record 属性指向下一个行数据，所以是可以遍历的，但是一组数据至多 8 个行，通过 Page Directory 先定位到组，然后遍历获取所需的数据行即可

数据行中有三个隐藏字段：trx_id、roll_pointer、row_id（在事务章节会详细介绍它们的作用）

---

#### BTree

BTree 的索引类型是基于 B+Tree 树型数据结构的，B+Tree 又是 BTree 数据结构的变种，用在数据库和操作系统中的文件系统，特点是能够保持数据稳定有序

‍

Tree 树就已经构建完成了，BTree 树和二叉树相比， 查询数据的效率更高， 因为对于相同的数据量来说，**BTree 的层级结构比二叉树少**，所以搜索速度快

BTree 结构的数据可以让系统高效的找到数据所在的磁盘块，定义一条记录为一个二元组 [key, data] ，key 为记录的键值，对应表中的主键值，data 为一行记录中除主键外的数据。对于不同的记录，key 值互不相同，BTree 中的每个节点根据实际情况可以包含大量的关键字信息和分支

缺点：当进行范围查找时会出现回旋查找

‍

### 设计原则

‍

索引的设计可以遵循一些已有的原则，创建索引的时候请尽量考虑符合这些原则，便于提升索引的使用效率

创建索引时的原则：

* 对查询频次较高，且数据量比较大的表建立索引
* 使用唯一索引，区分度越高，使用索引的效率越高
* 索引字段的选择，最佳候选列应当从 where 子句的条件中提取，使用覆盖索引
* 使用短索引，索引创建之后也是使用硬盘来存储的，因此提升索引访问的 I/O 效率，也可以提升总体的访问效率。假如构成索引的字段总长度比较短，那么在给定大小的存储块内可以存储更多的索引值，相应的可以有效的提升 MySQL 访问索引的 I/O 效率
* 索引可以有效的提升查询数据的效率，但索引数量不是多多益善，索引越多，维护索引的代价越高。对于插入、更新、删除等 DML 操作比较频繁的表来说，索引过多，会引入相当高的维护代价，降低 DML 操作的效率，增加相应操作的时间消耗；另外索引过多的话，MySQL 也会犯选择困难病，虽然最终仍然会找到一个可用的索引，但提高了选择的代价
* MySQL 建立联合索引时会遵守**最左前缀匹配原则**，即最左优先，在检索数据时从联合索引的最左边开始匹配  
  N 个列组合而成的组合索引，相当于创建了 N 个索引，如果查询时 where 句中使用了组成该索引的**前**几个字段，那么这条查询 SQL 可以利用组合索引来提升查询效率

  ```mysql
  -- 对name、address、phone列建一个联合索引
  ALTER TABLE user ADD INDEX index_three(name,address,phone);
  -- 查询语句执行时会依照最左前缀匹配原则，检索时分别会使用索引进行数据匹配。
  (name,address,phone)
  (name,address)
  (name,phone)	-- 只有name字段走了索引
  (name)

  -- 索引的字段可以是任意顺序的，优化器会帮助我们调整顺序，下面的SQL语句可以命中索引
  SELECT * FROM user WHERE address = '北京' AND phone = '12345' AND name = '张三';
  ```

  ```mysql
  -- 如果联合索引中最左边的列不包含在条件查询中，SQL语句就不会命中索引，比如：
  SELECT * FROM user WHERE address = '北京' AND phone = '12345'; 
  ```

哪些情况不要建立索引：

* 记录太少的表
* 经常增删改的表
* 频繁更新的字段不适合创建索引
* where 条件里用不到的字段不创建索引

---

‍

### 索引优化

#### 覆盖索引

覆盖索引：包含所有满足查询需要的数据的索引（SELECT 后面的字段刚好是索引字段），可以利用该索引返回 SELECT 列表的字段，而不必根据索引去聚簇索引上读取数据文件

回表查询：要查找的字段不在非主键索引树上时，需要通过叶子节点的主键值去主键索引上获取对应的行数据

使用覆盖索引，防止回表查询：

* 表 user 主键为 id，普通索引为 age，查询语句：

  ```mysql
  SELECT * FROM user WHERE age = 30;
  ```

  查询过程：先通过普通索引 age=30 定位到主键值 id=1，再通过聚集索引 id=1 定位到行记录数据，需要两次扫描 B+ 树
* 使用覆盖索引：

  ```mysql
  DROP INDEX idx_age ON user;
  CREATE INDEX idx_age_name ON user(age,name);
  SELECT id,age FROM user WHERE age = 30;
  ```

  在一棵索引树上就能获取查询所需的数据，无需回表速度更快

使用覆盖索引，要注意 SELECT 列表中只取出需要的列，不可用 SELECT *，所有字段一起做索引会导致索引文件过大，查询性能下降

---

#### 索引下推

索引条件下推优化（Index Condition Pushdown，ICP）是 MySQL5.6 添加，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数

索引下推充分利用了索引中的数据，在查询出整行数据之前过滤掉无效的数据，再去主键索引树上查找

* 不使用索引下推优化时存储引擎通过索引检索到数据，然后回表查询记录返回给 Server 层，**服务器判断数据是否符合条件**
* 使用索引下推优化时，如果**存在某些被索引的列的判断条件**时，由存储引擎在索引遍历的过程中判断数据是否符合传递的条件，将符合条件的数据进行回表，检索出来返回给服务器，由此减少 IO 次数

‍

**适用条件**：

* 需要存储引擎将索引中的数据与条件进行判断（所以**条件列必须都在同一个索引中**），所以优化是基于存储引擎的，只有特定引擎可以使用，适用于 InnoDB 和 MyISAM
* 存储引擎没有调用跨存储引擎的能力，跨存储引擎的功能有存储过程、触发器、视图，所以调用这些功能的不可以进行索引下推优化
* 对于 InnoDB 引擎只适用于二级索引，InnoDB 的聚簇索引会将整行数据读到缓冲区，不再需要去回表查询了

‍

#### 前缀索引

当要索引的列字符很多时，索引会变大变慢，可以只索引列开始的部分字符串，节约索引空间，提高索引效率

注意：使用前缀索引就系统就忽略覆盖索引对查询性能的优化了

优化原则：**降低重复的索引值**

比如地区表：

```mysql
area			gdp		code
chinaShanghai	100		aaa
chinaDalian		200		bbb
usaNewYork		300		ccc
chinaFuxin		400		ddd
chinaBeijing	500		eee
```

发现 area 字段很多都是以 china 开头的，那么如果以前 1-5 位字符做前缀索引就会出现大量索引值重复的情况，索引值重复性越低，查询效率也就越高，所以需要建立前 6 位字符的索引：

```mysql
CREATE INDEX idx_area ON table_name(area(7));
```

场景：存储身份证

* 直接创建完整索引，这样可能比较占用空间
* 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引
* 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题（前 6 位相同的很多）
* 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描

---

#### 索引合并

使用多个索引来完成一次查询的执行方法叫做索引合并 index merge

* Intersection 索引合并：

  ```sql
  SELECT * FROM table_test WHERE key1 = 'a' AND key3 = 'b'; # key1 和 key3 列都是单列索引、二级索引
  ```

  从不同索引中扫描到的记录的 id 值取**交集**（相同 id），然后执行回表操作，要求从每个二级索引获取到的记录都是按照主键值排序
* Union 索引合并：

  ```sql
  SELECT * FROM table_test WHERE key1 = 'a' OR key3 = 'b';
  ```

  从不同索引中扫描到的记录的 id 值取**并集**，然后执行回表操作，要求从每个二级索引获取到的记录都是按照主键值排序
* Sort-Union 索引合并

  ```sql
  SELECT * FROM table_test WHERE key1 < 'a' OR key3 > 'b';
  ```

  先将从不同索引中扫描到的记录的主键值进行排序，再按照 Union 索引合并的方式进行查询

索引合并算法的效率并不好，通过将其中的一个索引改成联合索引会优化效率

‍

‍

## 范式

Normal Format

减少数据的冗余

分为六层: 每一次层都比上一层更加严格: 若要满足下一层范式, 前提是满足上一层范式 --> 6NF是最高层,最严格

Mysql属于关系型数据库,致力于节省存储空间,会利用到范式来指导设计,但是数据库要保证效率问题,范式只为解决空间问题, 所以数据库不可能完全按照范式的要求实现(不是强制规范).

一般情况下, **只有前三种范式需要满足**

> 另见数据库原理

‍

### 概念

‍

#### **1NF 原子性**

字段的数据是不可再分基本数据项，同一列中不能有多个值，也不能存在重复的属性. 

第一范式是数据库的基本要求，不满足第一范式就不是**关系型**数据库

‍

‍

#### **2NF 唯一性**

在1NF基础上，消除非主属性对键的部分依赖

‍

‍

#### **3NF 关联性**

在2NF基础上，消除非主属性对键的传递依赖

‍

‍

### 性能取舍

‍

满足规范性VS性能

数据库性能更加重要时可以故意增加一些冗余的和计算列

‍

‍

## 备份还原

‍

备份    将当前已有的数据或者记录保留

还原    将已经保留的数据恢复到对应的表中

‍

‍

### MysqlDump

[Link](https://zhuanlan.zhihu.com/p/269983875)

‍

完整导出表结构和数据

```java
# 包括建库语句、表结构、数据
mysqldump -uroot -p2333 --host=localhost --port=3306 --databases ldbms_all> D:
```

‍

### 数据表

‍

不需要通过SQL来备份

直接进入到数据库文件夹复制对应的表结构以及数据文件, 以后还原的时候,直接将备份的内容放进去即可. (手动备份)

‍

‍

### 单表数据

‍

只能备份数据(表结构不能备份), 如果业务数据非常多，建议只导出表结构，然后用SELECT INTO OUTFILE把数据导出成文本文档

‍

备份: 从表中选出一部分数据保存到外部的文件中

```sql
Select */字段列表 into outfile 文件所在路径 from 数据源; 
-- 前提: 外部文件不存在
```

‍

还原: 将一个在外部保存的数据重新恢复到表中

```sql
Load data infile 文件所在路径 into table 表名[(字段列表)] fields字段处理 lines 行处理; 
-- 怎么备份的怎么还原
```

‍

‍

### SQL

‍

控制台备份的是SQL语句

系统会对表结构以及数据进行处理,变成对应的SQL语句, 然后进行备份: 还原的时候只要执行SQL指令即可.(主要就是针对表结构)

‍

**导出**

```sql
mysqldump -h主机 -u用户名 -p密码 数据库 [表名1,表名2...] >物理磁盘位置/文件名
```

‍

**导入**

```sql
source 备份文件
```

‍

‍

### 增量备份

‍

针对mysql服务器的日志文件进行备份, 指定时间段开始进行备份, 备份数据不会重复, 而且所有的操作都会备份(大项目都用增量备份)

‍

‍

### 大文件

‍

业务数据比较多的时候，只导出**表结构**到sql文件，业务数据文件导出到**txt文件**，这样就跳过了sql词法分析和语法优化，哪怕导入几千万条数据，也可以在1分钟内导入完毕

‍

1. 转储SQL文件->仅结构->(sql.脚本)
2. 导出向导(.txt)
3. 导入表结构,文本->导入向导(对应字段,选择模式)

‍

‍

‍

# 高级

‍

## 引擎

‍

### MyISAM

MyISAM索引文件和数据文件是分离的（非聚集索引）

> 存储结构
>
> ==叶子节点存放的是数据的地址==

‍

### InnoDB

InnoDB索引文件和数据文件是放在一起的（聚集索引）

* 表数据文件本身就是按照B+Tree组织的一个索引结构文件
* 是一个聚集索引
* InnoDB表必须有主键，并且推荐使用==整形==的==自增主键==。

  * 默认会拿主键id作为聚集索引
  * 如果没有主键，会取非空的唯一索引作为聚集索引
  * 如果以上都没有，InnoDB会自己维护一个唯一id作为聚集索引

  > ==整形==：整形数字的比较速度快，UUID字符串还要转换成ASCII表去比对
  >
  > ==自增主键==：InnoDB索引结构中，叶子节点通过指针连接，形成了有序的链表，如果主键不是自增，新增一个中间的主键，会导致索引表的分裂，重新整理
  >
  > 主键不自增，插入后会进行额外操作，这个过程会很耗时
  >

存储结构

==叶子节点会存放该数据的所有字段==

‍

#### 线程

(1) Master Thread

* 刷新脏页到磁盘
* 将日志缓冲刷新到磁盘
* undo页回收
* 合并插入缓冲

(2) IO Thread

* 通过Async IO 处理IO请求

(3) Purge Thread

* 回收已经不在使用的undo页

  > 事务提交之前，通过undolog（回滚日志）记录事务开始之前的状态。
  >
  > 当事务提交之后，该undolog日志就不在需要，需要Purge Thread线程回收
  >

(4) Page Cleaner Thread

* 脏页刷新，减轻Master负担，提升性能

‍

‍

‍

## 交互

‍

### Java连接

‍

使用Java连接Mysql的步骤

* 加载JDBC驱动程序
* 建立数据库连接Connection
* 创建执行SQL的语句Statement
* 处理执行结果ResultSet
* 释放连接资源

‍

‍

## 事务

‍

transaction

‍

事务    一系列要发生的连续的操作

事务安全    一种保护连续操作同时满足(实现)的一种机制,保证数据操作的完整性

‍

有些业务操作要多次访问数据库(发送多条SQL语句), 需要将多次访问数据库的操作视为一个整体来执行; 事务是一组操作的集合(一个不可分割的工作单位), 会把所有的操作作为一个整体一起向系统提交或撤销操作请求

事务开启之后, 所有的操作都会临时保存到事务日志, 事务日志只有在得到commit命令才会同步到数据表,其他任何情况<sup>（rollback, 断电, 断开连接）</sup>都会清空.

‍

作用：保证在一个事务中多次操作数据库表中数据时，要么全都成功,要么全都失败. 

‍

RDBMS关系数据库管理系统 = **SQL语句 + 事务(ACID)**

‍

‍

### 日志

‍

指记录SQL Server数据库执行的操作和事件的文件

SQL Server有多种类型的日志，其中最重要的是事务日志和错误日志. 

事务日志是记录数据库中所有事务以及每个事务所做的修改的文件. 事务日志支持数据库的恢复、复制、高可用性和灾难恢复等功能¹. 

错误日志是记录SQL Server实例启动、关闭、失败和错误信息的文件. 错误日志可以通过SQL Server Management Studio或者sp_readerrorlog存储过程来查看. 

‍

如果SQL语句直接操作文件是很危险的

> 比如你要给员工涨工资，正在update操作的时候，系统断电了，你就不知道谁已经涨了谁还没涨. 我们应该利用日志来间接写入.

‍

日志就相当于数据文件的一个**副本**，SQL语句操作什么样的记录，MySQL就会把这些记录拷贝到undo日志，然后增删改查的操作就会记录到redo日志，最后把redo日志和数据库文件进行同步就行了. 即使同步过程中断电了，有了redo日志的存在，重启MySQL数据库之后继续同步数据，同步成功后我们修改的数据就真正同步到数据库里面了，有事务的数据库抵抗风险的能力变强了. 

‍

‍

### 示例

‍

#### ​开启事务

‍

自动提交    即执行一条sql语句提交一次事务(默认,MySQL执行每条SQL语句都会自动开启和提交事务)

‍

手动提交    先开启，再提交

|SQL语句|描述|
| :------------------: | ------------------|
|start transaction;|开启手动控制事务|
|commit;|提交事务|
|rollback;|回滚事务|

‍

> 手动提交事务使用步骤：
>
> * 第1种情况：开启事务 => 执行SQL语句 => 成功 => 提交事务
> * 第2种情况：开启事务 => 执行SQL语句 => 失败 => 回滚事务

‍

‍

```sql
START TRANSACTION;

SQL语句

[COMMIT | ROLLBACK];  
```

‍

‍

#### 回滚点

‍

在某个成功的操作完成之后, 后续的操作有可能成功有可能失败, 但是不管成功还是失败前面操作都已经成功  
可以在当前成功的位置, 设置一个回滚点供后续失败操作返回到该位置, 而不是返回所有操作

‍

设置

```sql
    savepoint 回滚点名字;
```

‍

删除

```sql
    release savepoint 名字;
```

‍

还原

```sql
    rollback to 回滚点名字;
```

‍

示例

```sql
START TRANSACTION; #开启事务: 告诉系统以下所有的操作(写)不要直接写入到数据表, 先存放到redo日志。  
DELETE FROM t_emp;
SELECT * FROM t_emp;

#因为你开启了事务，你现在的操作还在redo日志里面，并没有同步到数据库文件只有COMMIT之后才会同步

COMMIT; #去数据表查看，2张数据表都被清空了。
ROLLBACK; # 当然你也可以直接回滚，执行ROLLBACK；

#这样你的redo日志被清空，下次操作的时候重新往redo日志里面进行操作，就不会受到上一次操作的影响。
```

‍

‍

### 属性

‍

**ACID**

‍

* 原子性（Atomicity）  事务是不可分割的最小单元，要么全部成功，要么全部失败. 事物执行后，不允许停留在中间某个状态.
* 一致性（Consistency）  事务完成时，必须使所有的数据都保持一致状态(最终一致性). 事务可以并发执行，但是最终MySQL却串行执行. 保证一致性即阻止事务之间相互读取临时数据
* 隔离性（Isolation）  数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行. 多个用户并发的访问数据库时，一个用户的事务不能被其他用户的事务干扰，多个并发的事务之间要相互隔离(一个事务的成功或者失败对于其他的事务没有影响)
* 持久性（Durability）  事务一旦提交或回滚，它对数据库中的数据的改变就是永久的. 哪怕数据库发生异常(发生宕机)，重启之后仍然可依靠事务日志完成数据持久化

‍

‍

### 隔离性

‍

想让事务之间读取到一些临时数据，需要修改事务的隔离级别

隔离有**可序列化隔离**和**弱隔离(** 也叫**不可序列化隔离)**

‍

‍

‍

#### 设置

==设置事务隔离级别==

```sql
SET [PERSIST|GLOBAL|SESSION]  
    TRANSACTION ISOLATION LEVEL
    { # 四选一
       READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE
    }
 
-- PERSIST:所有连接到mysql服务的新的连接都有效，并且mysql服务器重启后也不会丢失修改
-- GLOCAL: 所有连接到mysql服务的新的连接都有效，但是mysql服务器重启后会丢失这个修改
-- SESSION：开发最常用，只会影响到当前连接，当前连接断开，这个隔离级别的修改就会丢失
 
-- 开发中也可以用show variables like '%iso%'查看当前session的隔离级别
-- 因为有一个变量参数名为transaction_isolation
```

‍

#### 错误类型

由于事务并发执行所带来的各种问题, 前三种隔离级别只适用于某种业务场景

‍

|**事务的隔离级别**|**脏读**|**不可重复读**|**幻读**|
| -------------------| --| --| --|
|**Read uncommitted**| **√**| **√**| **√**|
|**Read committed--Sql Server , Oracle**| **×**| **√**| **√**|
|Repeatable read--**MySQL**| **×**| **×**| **√**|
|**Serializable**| **×**| **×**| **×**|

‍

‍

##### ==脏读==

事务 A 读取了事务 B 当前更新的数据，但是事务 B 出现了回滚或未提交修改，事务 A 读到的数据就被称为 “脏数据”

‍

##### ==幻读==

A在执行过程中读取了一些数据，B随即**插入一些数据**. A 重新读取时发现多了一些原本不存在的数据，就像是幻觉一样<sup>（不可重复读指的是对原来存在的数据做修改，而幻读指的是新增或者删除数据）</sup>

‍

##### ==不可重复读==

事务 A 在执行过程中多次读取同一数据，但是事务 B 在事务 A 的读取过程中对数据做了多次**修改并提交**，则会导致事务 A 多次读取的数据不一致，进而无法做出准确性判断

‍

‍

#### 隔离级别

==由低到高隔离级别和对应的功能,下一级别包含上一级别==

1. read uncommitted    未提交读
2. read committed    已提交读  SQL Server默认的隔离级别
3. repeatable read    重复读取
4. serializable    序列化

‍

##### read uncommitted

读未提交(啥都看)        ==隔离性最低，并发性最高==

读未提交会出现    **脏读、不可重复读、幻读 **​*所有问题*

‍

‍

> 还剩最后一张票，A点击购买还没付款提交，因为查看不到事务之间的临时数据，所以B查看时，也还剩一张票，结果A购买失败;  
> 所以如果互相能看见,则没有问题

> 脏读, 读到了别的事务回滚前的脏数据

限制性最弱的隔离级别，因为该级别忽略其他事务放置的锁. 使用READ UNCOMMITTED级别执行的事务，可以读取尚未由其他事务提交的修改后的数据值，这些行为称为“脏”读. 这是因为在Read Uncommitted级别下，读取数据不需要加S锁，这样就不会跟被修改的数据上的X锁冲突

‍

‍

##### read committed

读已提交    也叫不可重复读(只能看到已经提交的数据)

读已提交会出现    **不可重复读、幻读**

‍

‍

> A事务往账户转账1000，B事务扣除100，如果A能读取到B事务未提交的数据，那么转账后就会独立合并计算修改为5900; 而此时回滚支出100元，此时账户就只有5900块了  
>
> 所以应该限制A事务读取到B事务**提交后的数据**

> 不可重复读: 当前事务先进行了一次数据读取，然后再次读取到的数据是别的事务修改成功的数据

SQL Server默认的隔离级别. 该级别通过指定语句不能读取其他事务已修改但是尚未提交的数据值，禁止执行脏读. 

在当前事务中的各个语句执行之间，其他事务仍可以修改、插入或删除数据，从而产生无法重复的读操作，或“影子”数据. 比如，事务1读取了一行，事务2修改或者删除这一行并且提交. 如果事务1想再一次读取这一行，它将获得修改后的数据或者发现这一样已经被删除，因此事务的第二次读取结果与第一次读取结果不同，因此也叫不可重复读

‍

‍

##### repeatable read

可重复读    类似多线程加锁机制(只能看到已经提交的数据)

可重复读会出现    **幻读**

‍

> 点击提交订单，此时显示的价格是undo日志的价格，如果此时卖家涨价，你购买的还是涨价之前的价格.

> 幻读, 眼睛花了, 看两次的结果不一样, 第一次看之后有其他人动了东西

指定了在当前事务提交之前，其他任何事务均不可以修改或删除当前事务已读取的数据. 并发性低于 READ COMMITTED，因为已读数据的共享锁在整个事务期间持有，而不是在每个语句结束时释放. 比如，事务1读取了一行，事务2想修改或者删除这一行并且提交，但是因为事务1尚未提交，数据行中有事务1的锁，事务2无法进行更新操作，因此事务2阻塞. 如果这时候事务1想再一次读取这一行，它读取结果与第一次读取结果相同，因此叫可重复读. 

但是可重复读操作并不是特定指两次读取的数据一模一样，Repeatable Read存在的问题是幻读，就是第二次读取的数据返回的条目数比第一次返回的条目数更多

‍

**只有靠锁才能保证不出现幻读的问题**

> 应用中可以考虑使用**Redis分布式锁**

‍

‍

##### serializable

序列化    隔离性最高(所有事务按照顺序执行)

*序列化单线程, 没有出问题可能*

‍

> 使用情境少，让事务的并发性大大降低.

‍

限制性最强的隔离级别，因为该级别锁定整个范围的键，并一直持有锁，直到事务完成. 

该级别包括 REPEATABLE READ，并增加了在事务完成之前，其他事务不能向事务已读取的范围插入新行的限制. 

比如，事务1读取了一系列满足搜索条件的行. 事务2在执行SQL statement产生一行或者多行满足事务1搜索条件的行时会冲突，则事务2回滚. 这时事务1再次读取了一系列满足相同搜索条件的行，第二次读取的结果和第一次读取的结果相同. 

‍

‍

‍

### 锁

‍

#### 类型

‍

##### **共享锁 / S锁 / 读锁**

若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务**只能再对A加S锁，而不能加X锁**，直到T释放A上的S锁. 

这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改. 

‍

##### **排他锁 / X锁 / 写锁**

若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务**不能再对A加任何锁**，直到T释放A上的锁. 

这保证了其他事务在T释放A上的锁之前不能再读取和修改A. 

‍

‍

#### 策略

* 在Read Uncommitted级别下，读操作不加S锁
* 在Read Committed级别下，读操作需要加S锁，但是在语句执行完以后释放S锁
* 在Repeatable Read级别下，读操作需要加S锁，但是在事务提交之前并不释放S锁，也就是必须等待事务执行完毕以后才释放S锁
* 在Serialize级别下，会在Repeatable Read级别的基础上，添加一个范围锁. 保证一个事务内的两次查询结果完全一样，而不会出现第一次查询结果是第二次查询结果的子集

‍

‍

‍

‍

## 视图

‍

视图是从一个或者多个表或视图中导出的表，其结构和数据是建立在对表的查询基础上的。和真实的表一样，视图也包括几个被定义的数据列和多个数据行，但从本质上讲，这些数据列和数据行来源于其所引用的表。因此，视图不是真实存在的基础表而是一个虚拟表，视图所对应的数据并不实际地以视图结构存储在数据库中，而是存储在视图所引用的表中。

‍

* 视图定义只在数据字典中存定义，不存数据并且不会执行基表的查询
* 执行视图定义语句的时候只是把定义存入数据字典, 并不执行语句

一种有结构(有行有列)但是没结果的虚拟表, 结构从对应的基表中产生

‍

### **特点**

* 结构中不真实存放数据
* 查看表(视图)的创建语句的时候可以使用view关键字
* 视图一旦创建, 系统会在视图对应的数据库文件夹下创建一个对应的结构文件(frm文件)
* 视图可以节省SQL语句: 将一条复杂的查询语句使用视图进行保存, 以后可以直接对视图进行操作
* 数据安全: 视图操作是主要针对查询的, 如果对视图结构进行处理(删除), 不会影响基表数据(相对安全).可以对外提供有用的数据, 但是隐藏关键(无用)的数据, 保证了数据安全
* 视图可以更好(容易)的进行权限控制

‍

### 定义

**行列子集视图**    从单个基本表导出的, 并且只是屏蔽了一些行列(保留主码)

**分组视图**    使用聚集函数和Group By子句定义的视图

**视图消解**    通过结合视图定义中的子查询和用户的查询，将对视图的查询转换为等价的对基本表的查询

‍

‍

### CRUD

‍

#### **创建**

‍

```sql
Create view 视图名字 as select语句;
```

‍

创建单表视图: 基表只有一个  创建多表视图: 基表来源至少两个

‍

**CREATE** **VIEW &lt;Name&gt;；**

视图建立在基本表上

```java
CREATE VIEW IS_Student 
AS 
SELECT Sno，Sname，Sage
FROM Student 
WHERE Sdept=IS;
```

‍

视图建立在已经定义好的视图上

FROM 视图即可

‍

‍

#### **删除**

**DROP VIEW&lt;视图名&gt;[CASCADE]；**

‍

删除视图的时候,如果该视图上还导出了其他的视图,那么不能删除,需要在后面加CASCADE,即级联操作,进而把该视图和它导出的所有视图删除

‍

```sql
Drop view 视图名字;
```

‍

‍

#### **修改**

```sql
Alter view 视图名字 as 新的select语句;
```

‍

视图本身不可修改, 但是视图的来源是可以修改的->修改来源语句

‍

‍

#### **查看**

> 视图是一张虚拟表,表的所有查看方式都适用于视图

‍

```sql
show tables [like]
```

```sql
desc 视图名字
```

‍

建表语句

```sql
show create table 视图名;
```

‍

### 作用

* 简化用户操作
* 多角度看待同一数据
* 对重构数据库提供逻辑独立性
* 保护机密数据
* 优化查询

‍

## 触发器

‍

事先为某张表绑定好一段代码, 当表中的某些内容发生改变的时候系统会自动触发代码执行, 可以很好的协调表内部的数据处理顺序和关系

‍

特点

* 一张表最多能有6个触发器, 并且只能拥有**一种触发时间的一种类型的触发器**
* 但是从JAVA角度出发, 触发器会增加数据库维护的难度, 所以较少使用触发器.

‍

### 要素

‍

事件类型    增删改insert,delete,update

触发时间    前后before,after

触发对象    表中的每一条记录(行)

‍

‍

### CRUD

‍

#### **创建**

如果触发器内部只有一条要执行的SQL指令, 可以省略大括号(begin和end)

-- 临时修改语句结束符  
Delimiter 自定义符号: 后续代码中只有碰到自定义符号才算结束

‍

```sql
Create trigger 触发器名字 触发时间 事件类型 on 表名 for each row
```

Begin -- 代表左大括号: 开始

‍

-- 里面就是触发器的内容: 每行内容都必须使用语句结束符: 分号

‍

End -- 代表右带括号: 结束

‍

-- 语句结束符

自定义符号

‍

-- 将临时修改修正过来

Delimiter  ;

‍

‍

insert 触发器的创建

在 STUMS 数据库的教师表上创建一个名为 js_insert_trigger 的触发器，当执行 INSERT 操作时，该触发器被触发，提示 “ 禁止插入记录！” 。

```sql
CREATE TRIGGER js_insert_trigger ON 教师
FOR INSERT 
AS   
BEGIN
PRINT('禁止插入记录！')
ROLLBACK TRANSACTION
END
GO
```

‍

delete 触发器的创建

在 STUMS 数据库的教师表上创建一个名为 js_delete_trigger 的触发器，当执行 DELETE 操作时，该触发器被触发，提示 “ 禁止删除记录！” 。  
代码如下

```sql
USE STUMS
GO
CREATE TRIGGER js_delete_trigger ON 教师
FOR DELETE
AS
BEGIN
PRINT('禁止删除记录！')
ROLLBACK TRANSACTION
END
GO

```

‍

多表级联插入触发器

在 STUMS 数据库的学生基本信息表上创建一个名为 xs_insert_trigger 的触发器，当在学生基本信息表中插入记录时，将该记录中的学号自动插入 Student 表。

‍

```sql
USE STUMS
GO
CREATE TRIGGER xs_insert_trigger ON 学生基本信息
FOR INSERT
AS
DECLARE @XH CHAR(9)  /*定义局部变量*/
SELECT @XH = 学号 FROM INSERTED  /*从INSERTED表中取出学号赋给变量@XH */
INSERT Student(学号)
VALUES(@XH)   /*将变量@XH的值插入到选课表*/
GO

```

‍

‍

#### **查看**

‍

查看所有触发器或者模糊匹配

```sql
Show triggers [like ‘pattern’];
```

‍

查看触发器创建语句

```sql
Show create trigger 触发器名字;
```

‍

\g 的作用是分号和在sql语句中写’;’是等效的  
\G 的作用是将查到的结构旋转90度变成纵向

‍

所有的触发器都会保存一张表 -> Information_schema.triggers

‍

‍

#### **删除**

‍

> 不能修改, 只能先删除, 后新增

```sql
Drop trigger 触发器名字;
```

‍

‍

‍

#### **记录**

‍

不管触发器是否触发了,只要当某种操作准备执行, 系统就会将当前要操作的记录的当前状态和即将执行之后新的状态给分别保留下来, 供触发器使用

其中, 要操作的当前状态保存到old中, 操作之后的可能形态保存给new

‍

Old代表的是旧记录, new代表的是新记录

删除的时候是没有new的; 插入的时候是没有old

Old和new都是代表记录本身: 任何一条记录除了有数据, 还有字段名字.

‍

使用方式: old.字段名 / new.字段名(new代表的是假设发生之后的结果)

‍

‍

‍

## 函数

‍

### 数字函数

‍

ABS    绝对值

ROUND    四舍五入

CEIL    强制进位到最近整数

FLOOR    强制舍位到最近整数

POWER    幂函数

LOG/LN    对数函数

SQRT    开平方

PI    圆周率

​​

‍

‍

### 日期函数

‍

* 两个日期不能直接加减，日期也不能与数字加减
* 数据库的最小时间单位是秒s，而不是毫秒ms

‍

‍

#### **获取系统时间**

‍

NOW()    获得系统日期和时间，格式yyyy-MM-dd hh:mm:ss  

CURDATE()    获得当前系统日期，格式yyyy-MM-dd  

CURTIME()    获得当前系统时间，格式hh:mm:ss

```sql
SELECT NOW(), CURDATE(), CURTIME();
```

‍

#### **日期格式化**

‍

DATE_FORMAT(日期,  表达式)

```sql
SELECT ename, DATE_FORMAT(hiredate,"%Y") AS result FROM t_emp;
```

‍

‍

#### **占位符**

‍

%Y    年

%m    月份

%d    日期

%W/w    星期(数字/名称)

%H/h    小时(24/12)

%i    分钟

%s    秒

%T/r   时间(24/12)

‍

‍

#### **日期偏移计算**

‍

DATE_ADD(日期, INTERVAL 偏移量  偏移的时间单位)

SELECT DATEDIFF(NOW(),"2019-1-1");  日期之间相隔的天数

‍

```sql
/*100天之后是什么时间*/
SELECT DATE_ADD(NOW(), INTERVAL 100 DAY);
/*300分钟之前是什么时间*/
SELECT DATE_ADD(NOW(), INTERVAL -300 MINUTE);
/*6个月零3天之前是什么时间*/
SELECT DATE_ADD(DATE_ADD(NOW(),INTERVAL -6 MONTH),INTERVAL -3 DAY)
```

‍

‍

### 字符函数

‍

LOWER/UPPER    转换小写/大写

LENGTH    字符数量

CONCAT    连接字符串

INSTR    字符出现位置

INSERT    插入/替换字符

REPLACE    替换字符

SUBSTR    截取字符串

TRIM    去除首尾

‍

​​

### 条件函数

‍

```sql
IFNULL(表达式, 值)
IF(表达式, 值1, 值2)
```

```sql
CASE
    WHEN 表达式 THEN 值1
    WHEN 表达式 THEN 值2
    ...
    ELSE 值N
END
```

‍

‍

### 自定义函数

‍

函数要素

‍

函数名, 参数列表(形参和实参), 返回值, 函数体(作用域)

‍

#### 基本操作

‍

##### **创建**

‍

```sql
Create function  函数名([形参列表]) returns 数据类型 -- 规定要返回的数据类型

Begin

-- 函数体

-- 返回值: return 类型(指定数据类型);

End
```

‍

‍

##### **查看**

‍

查看所有函数

```sql
show function status [like ‘pattern’];
```

‍

查看函数的创建语句

```sql
show create function 函数名;
```

‍

‍

##### **删除**

‍

删除后新增, 不能修改.

```sql
Drop function 函数名;
```

‍

‍

#### 函数参数

‍

形参要求必须指定数据类型

在函数内部使用 @ 定义的变量在函数外部也可以访问

```sql
Function 函数名(形参名字 字段类型) returns 数据类型
```

‍

‍

#### 作用域

Mysql中的作用域与js中的作用域完全一样

全局变量可以在任何地方使用; 局部变量只能在函数内部使用.

全局变量: 使用set关键字定义, 使用@符号标志

局部变量: 使用declare关键字声明, 没有@符号: 所有的局部变量的声明,必须在函数体开始之前

‍

‍

‍

### 存储过程

procedure

简称过程, 一种用来处理数据的方式, 是一种没有返回值的函数

‍

‍

**创建**

‍

Create procedure 过程名字([参数列表])

Begin

-- 过程体

End

‍

#### 基本操作

‍

##### **查看**

‍

函数的查看方式完全适用于过程: 关键字换成procedure

‍

查看所有过程

```sql
show procedure status [like ‘pattern’];
```

‍

查看过程创建语句

```sql
show create procedure 过程名;
```

‍

‍

##### **调用**

‍

过程没有返回值: select是不能访问的.

调用关键字

```sql
call
```

‍

‍

##### **删除**

‍

先删除,后新增

```sql
Drop procedure 过程名;
```

‍

‍

#### 过程参数

‍

参数需要数据类型指定, 过程比函数更严格

‍

过程还有自己的类型限定

‍

三种类型

‍

In: 数据只是从外部传入给内部使用(值传递): 可以是数值也可以是变量

Out: 只允许过程内部使用(不用外部数据), 给外部使用的.(引用传递: 外部的数据会被先清空才会进入到内部): 只能是变量

Inout: 外部可以在内部使用,内部修改也可以给外部使用: 典型的引用传递: 只能传变量

‍

```SQL
    Create procedure 过程名(in 形参名字 数据类型, out 形参名字 数据类型, inout 形参名字 数据类型)
```

  
调用: out和inout类型的参数必须传入变量,而不能是数值

  
存储过程对于变量的操作(返回)是滞后的: 是在存储过程调用结束的时候,才会重新将内部修改的值赋值给外部传入的全局变量.

‍

‍

## 连接池

‍

一般数据库重复连接-释放耗费资源

> 创建一个新的连接对象，然后执行SQL语句,然后又需要关闭连接对象从而释放资源: 每次执行SQL时都需要创建连接、销毁链接

‍

数据库连接池技术(池化技术)避免频繁的创建连接、销毁连接而带来的资源浪费

数据库连接池是个容器，负责分配、管理数据库连接

‍

‍

### 优点

‍

* 资源重用
* 提升系统响应速度
* 避免数据库连接遗漏

‍

‍

### 功能

‍

允许程序重复使用一个现有的数据库连接，而不是再重新建立一个

Connection对象可以复用

> 执行SQL时先从连接池中获取一个Connection对象，执行之后释放Connection时就会把Connection归还

‍

释放空闲时间超过最大空闲时间的连接，来避免因为没有释放连接而引起的数据库连接遗漏

‍

‍

### 实现

‍

实现数据库连接池

官方提供数据库连接池标准<sup>（javax.sql.DataSource接口）</sup>, 第三方组织必须按照DataSource接口实现.

常见的数据库连接池中使用更多的是：Hikari（追光者,默认)、Druid（德鲁伊）

‍

‍

## SQL注入

‍

由于没有对用户输入内容进行充分检查，而SQL又是字符串拼接方式而成，在用户输入参数时，在参数中添加一些SQL关键字，达到改变SQL运行结果的目的，从而完成恶意攻击. 

利用预编译的模式,能够将传入的整个`' or '1'='1`​作为一个完整的参数，赋值给第2个问号（`' or '1'='1`​进行了转义，只当做字符串使用）

‍

‍

## 预编译

> 见Spring整合内容

‍

**优势**

1. 性能更高, 采用?匹配, 不是写死的
2. 更安全(防止SQL注入)

‍

‍

## 主从复制-读写分离

> 目前所有的读和写的压力都是由一台数据库来承担，如果数据库服务器磁盘损坏，则数据会丢失（没有备份）
>
> 解决这个问题，就可以用MySQL的主从复制，写操作交给主库，读操作交给从库, 同时将主库写入的内容，同步到从库中

* 面对日益增加的系统访问量，数据库的吞吐量面临着巨大的瓶颈.
* 对于同一时刻有`大量并发读操作`​和`较少的写操作`​类型的应用系统来说，将数据库拆分为`主库`​和`从库`​
* ​`主库`​主要负责处理事务性的增删改操作
* ​`从库`​主要负责查询操作
* 这样就能有效避免由数据更新导致的行锁，使得整个系统的查询性能得到极大的改善

MySQL主从复制是一个异步的复制过程，底层是基于Mysql数据库自带的二进制日志功能. 就是一台或多台NysQL数据库（slave，即从库）从另一台MySQL数据库(master，即主库）进行日志的复制然后再解析日志并应用到自身，最终实现从库的数据和主库的数据保持一致. MySQL主从复制是MySQL数据库自带功能，无需借助第三方工具.

‍

分成三步

1. ​`maste`​r将改变记录到二进制日志(`binary log`​)
2. ​`slave`​将`master`​的`binary log`​拷贝到它的中继日志(`relay log`​)
3. ​`slave`​重做中继日志中的事件，将改变应用到自己的数据库中

‍

‍

### 配置

‍

‍

#### 前置

两台服务器，分别安装MySQL并启动服务成功，我这里用的两台虚拟机（另一台是克隆的，记得修改克隆虚拟机的MySQL的UUID）

‍

修改克隆机的MySQL的uuid

登录克隆机的MySQL

‍

执行SQL语句，记住生成的uuid

```java
mysql> select uuid();
+--------------------------------------+
| uuid()                               |
+--------------------------------------+
| 26532364-4f8d-11ed-a300-005056307198 |
+--------------------------------------+
```

‍

查看配置文件目录

```java
mysql> show variables like 'datadir';
+---------------+-----------------+
| Variable_name | Value           |
+---------------+-----------------+
| datadir       | /var/lib/mysql/ |
+---------------+-----------------+
```

‍

编辑配置文件目录，修改uuid为刚刚我们生成的uuid

```java
vi /var/lib/mysql/auto.cnf
```

‍

重启服务

```
service mysqld restart
```

‍

‍

#### 配置主库

‍

‍

修改MySQL数据库的配置文件，虚拟机是`/etc/my.cnf`​

找到`[mysqld]`​，在下面插入两行

> log_bin=mysql-bin #[必须]启用二进制日志  
> server-id=128 #[必须]服务器唯一ID,只需要确保其id是唯一的就好

‍

‍

重启mysql服务

```
systemctl restart mysqld
```

‍

登录Mysql数据库,执行下面的SQL

```
grant replication slave on *.* to 'Slave'@'%' identified by '2333';
```

‍

上面的SQL的作用是创建一个用户`Kyle`​,密码为`root`​，并且给`Kyle`​用户授予`replication slave`​权限，常用语建立复制时所需要用到的用户权限，也就是`slave`​必须被`master`​授权具有该权限的用户，才能通过该用户复制，这是因为主库和从库之间需要互相通信，处于安全考虑，只有通过验证的从库才能从主库中读取二进制数据

‍

登录Mysql数据库,执行下面的SQL

```
show master status;
```

‍

记录下结果中File和Position的值

```
+------------------+----------+--------------+------------------+-------------------+
| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
+------------------+----------+--------------+------------------+-------------------+
| mysql-bin.000005 |      154 |              |                  |                   |
+------------------+----------+--------------+------------------+-------------------+
```

‍

‍

#### 配置从库

‍

修改MySQL数据库的配置文件`/etc/my.cnf`​

‍

找到`[mysqld]`​，在下面插入一行

> server-id=127 #[必须]服务器唯一ID,只需要确保其id是唯一的就好

‍

重启mysql服务

```
systemctl restart mysqld
```

‍

登录Mysql数据库,执行下面的SQL

```
change master to master_host='192.168.238.131',master_user='Kyle',master_password='root',master_log_file='mysql-bin.000005',master_log_pos=154;
start slave;
```

‍

上面的SQL的作用是创建一个用户`Kyle`​,密码为`root`​，并且给`Kyle`​用户授予`replication slave`​权限，常用语建立复制时所需要用到的用户权限，也就是`slave`​必须被`master`​授权具有该权限的用户，才能通过该用户复制，这是因为主库和从库之间需要互相通信，处于安全考虑，只有通过验证的从库才能从主库中读取二进制数据

‍

登录Mysql数据库,执行SQL，查看从库的状态

```
show slave status;
```

‍

‍

看到输出中有如下如下三行配置相同，则主从连接成功

> Slave_IO_State: Waiting for master to send event  
> Slave_IO_Running: Yes  
> Slave_SQL_Running: Yes

‍

‍

#### 兼容

‍

Spring中用Sharding-JDBC

‍

‍

## SQL SERVER权限管理

‍

SQL Server权限管理策略

* 安全帐户认证

  * 安全帐户认证是用来确认登录SQL Server的用户的登录帐号和密码的正确性，由此来验证其是否具有连接SQL Server的权限。 SQL Server 2000提供了两种确认用户的认证模式：

    * （一）Windows NT认证模式。

      * SQL Server数据库系统通常运行在Windows NT服务器平台上，而NT作为网络操作系统，本身就具备管理登录、验证用户合法性的能力，因此Windows NT认证模式正是利用了这一用户安全性和帐号管理的机制，允许SQL Server也可以使用NT的用户名和口令。在这种模式下，用户只需要通过Windows NT的认证，就可以连接到SQL Server，而SQL Server本身也就不需要管理一套登录数据。
    * （二）混合认证模式。

      * 混合认证模式允许用户使用Windows NT安全性或SQL Server安全性连接到SQL Server，这就意味着用户可以使用他的帐号登录到Windows NT，或者使用他的登录名登录到SQL Server系统。NT的用户既可以使用NT认证，也可以使用SQL Server认证
* 访问许可确认

  * 但是通过认证阶段并不代表用户能够访问SQL Server中的数据，同时他还必须通过许可确认。用户只有在具有访问数据库的权限之后，才能够对服务器上的数据库进行权限许可下的各种操作，这种用户访问数据库权限的设置是通过用户帐号来实现的。

‍

用户权限管理

* 服务器登录帐号和用户帐号管理

  * 1.利用企业管理器创建、管理SQL Server登录帐号

    * （１）打开企业管理器，单击需要登录的服务器左边的“+”号，然后展开安全性文件夹。
    * （２）用右键单击登录（login）图标，从快捷菜单中选择新建登录（new login）选项，则出现SQL Server登录属性—新建登录对话框，如图6-2所示。
    * （3）在名称编辑框中输入登录名，在身份验证选项栏中选择新建的用户帐号是Windows NT认证模式，还是SQL Server认证模式。
    * （４）选择服务器角色页框。在服务器角色列表框中，列出了系统的固定服务器角色。
    * （５）选择用户映射页框。上面的列表框列出了该帐号可以访问的数据库，单击数据库左边的复选框，表示该用户可以访问相应的数据库以及该帐号在数据库中的用户名。
    * （６）设置完成后，单击“确定”按钮即可完成登录帐号的创建。
  * 使用SQL 语句创建登录帐号
  * 2.用户帐号管理

    * 在数据库中，一个用户或工作组取得合法的登录帐号，只表明该帐号通过了Windows NT认证或者SQL Server认证，但不能表明其可以对数据库数据和数据库对象进行某种或者某些操作，只有当他同时拥有了用户权限后，才能够访问数据库。
    * 利用企业管理器可以授予SQL Server登录访问数据库的许可权限。使用它可创建一个新数据库用户帐号
* 许可（权限）管理

  * 许可用来指定授权用户可以使用的数据库对象和这些授权用户可以对这些数据库对象执行的操作。用户在登录到SQL Server之后，其用户帐号所归属的NT组或角色所被赋予的许可（权限）决定了该用户能够对哪些数据库对象执行哪种操作以及能够访问、修改哪些数据。在每个数据库中用户的许可独立于用户帐号和用户在数据库中的角色，每个数据库都有自己独立的许可系统，在SQL Server中包括三种类型的许可：即对象许可、语句许可和预定义许可。

    * 三种许可类型

      * 1、对象许可

        * 表示对特定的数据库对象，即表、视图、字段和存储过程的操作许可，它决定了能对表、视图等数据库对象执行哪些操作。
      * 2、语句许可

        * 表示对数据库的操作许可，也就是说，创建数据库或者创建数据库中的其它内容所需要的许可类型称为语句许可。
      * 3、预定义许可

        * 是指系统安装以后有些用户和角色不必授权就有的许可。
* 角色管理

  * 角色是SQL Server 7.0版本引进的新概念，它代替了以前版本中组的概念。利用角色，SQL Server管理者可以将某些用户设置为某一角色，这样只对角色进行权限设置便可以实现对所有用户权限的设置，大大减少了管理员的工作量。SQL Server提供了用户通常管理工作的预定义服务器角色和数据库角色。

    * 1、服务器角色

      * 服务器角色是指根据SQL Server的管理任务，以及这些任务相对的重要性等级来把具有SQL Server管理职能的用户划分为不同的用户组，每一组所具有的管理SQL Server的权限都是SQL Server内置的，即不能对其进行添加、修改和删除，只能向其中加入用户或者其他角色。
      * 几种常用的固定服务器角色

        * 系统管理员：拥有SQL Server所有的权限许可。
        * 服务器管理员：管理SQL Server服务器端的设置。
        * 磁盘管理员：管理磁盘文件。
        * 进程管理员：管理SQL Server系统进程。
        * 安全管理员：管理和审核SQL Server系统登录。
        * 安装管理员：增加、删除连接服务器，建立数据库复制以及管理扩展存储过程。
        * 数据库创建者：创建数据库，并对数据库进行修改。
    * 2、数据库角色

      * 数据库角色是为某一用户或某一组用户授予不同级别的管理或访问数据库以及数据库对象的权限，这些权限是数据库专有的，并且还可以使一个用户具有属于同一数据库的多个角色。SQL Server提供了两种类型的数据库角色：即固定的数据库角色和用户自定义的数据库角色。
      * （１）固定的数据库角色

        * public：维护全部默认许可。
        * db_owner：数据库的所有者，可以对所拥有的数据库执行任何操作。
        * db_accessadmin：可以增加或者删除数据库用户、工作组和角色。
        * db_addladmin：可以增加、删除和修改数据库中的任何对象。
        * db_securityadmin：执行语句许可和对象许可。
        * db_backupoperator：可以备份和恢复数据库。
        * db_datareader：能且仅能对数据库中的任何表执行select操作，从而读取所有表的信息。
        * db_datawriter：能够增加、修改和删除表中的数据，但不能进行select操作。
        * db_denydatareader：不能读取数据库中任何表中的数据。
        * db_denydatawriter：不能对数据库中的任何表执行增加、修改和删除数据操作。
      * （２）用户自定义角色

        * 创建用户定义的数据库角色就是创建一组用户，这些用户具有相同的一组许可。如果一组用户需要执行在SQL Server中指定的一组操作并且不存在对应的Windows NT组，或者没有管理Windows NT用户帐号的许可，就可以在数据库中建立一个用户自定义的数据库角色。用户自定义的数据库角色有两种类型：即标准角色和应用程序角色。

‍

Transaction_SQL 语句

* 赋权语句——Grant
* 收回权限——Revoke
* 收回权限——Deny

‍

## MVCC

‍

多版本控制(MVCC) **Multi-Version Concurrency Control**: 指的是一种提高并发的技术。最早的数据库系统，只有读读之间可以并发，读写，写读，写写都要阻塞。引入多版本之后，只有写写之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了InnoDB的并发度。在内部实现中，InnoDB通过undo log保存每条数据的多个版本，并且能够找回数据历史版本提供给用户读，每个事务读到的数据版本可能是不一样的。在同一个事务中，用户只能看到该事务创建快照之前已经提交的修改和该事务本身做的修改。

MVCC只在 Read Committed 和 Repeatable Read两个隔离级别下工作。其他两个隔离级别和MVCC不兼容，Read Uncommitted总是读取最新的记录行，而不是符合当前事务版本的记录行；Serializable 则会对所有读取的记录行都加锁。

MySQL的InnoDB存储引擎默认事务隔离级别是RR(可重复读)，是通过 "行级锁+MVCC"一起实现的，正常读的时候不加锁，写的时候加锁。而 MVCC的实现依赖：隐藏字段、Read View、Undo log

‍

优点

* 提高并发性能：读操作不会阻塞写操作，写操作也不会阻塞读操作，有效地提高数据库的并发性能。
* 降低死锁风险：由于无需使用显式锁来进行并发控制，MVCC 可以降低死锁的风险。

‍

### 当前读和快照读

在讲解 MVCC 原理之前，我们先来了解一下，当前读和快照读。

‍

#### 当前读

当前读实际上是一种加锁的操作，是悲观锁的实现。

在 MySQL 中，当前读是一种读取数据的操作方式，它可以直接读取最新的数据版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。MySQL 提供了两种实现当前读的机制：

* 一致性读（Consistent Read）：  
  默认隔离级别下（可重复读），MySQL 使用一致性读来实现当前读。  
  在事务开始时，MySQL 会创建一个一致性视图（Consistent View），该视图反映了事务开始时刻数据库的快照。  
  在事务执行期间，无论其他事务对数据进行了何种修改，事务始终使用一致性视图来读取数据。  
  这样可以保证在同一个事务内多次查询返回的结果是一致的，从而实现了当前读。
* 锁定读（Locking Read）：  
  锁定读是一种特殊情况下的当前读方式，在某些场景下使用。  
  当使用锁定读时，MySQL 会在执行读取操作前获取共享锁或排他锁，以确保数据的一致性。  
  共享锁（Shared Lock）允许多个事务同时读取同一数据，而排他锁（Exclusive Lock）则阻止其他事务读取或写入该数据。  
  锁定读适用于需要严格控制并发访问的场景，但由于加锁带来的性能开销较大，建议仅在必要时使用。

下面列举的这些语法都是当前读：

* SELECT ... LOCK IN SHARE MODE
* SELECT ... FOR UPDATE
* UPDATE
* DELETE
* lNSERT

‍

#### **快照读**

快照读是在读取数据时读取一个一致性视图中的数据，MySQL 使用 MVCC 机制来支持快照读。

具体而言，每个事务在开始时会创建一个一致性视图（Consistent View），该视图反映了事务开始时刻数据库的快照。这个一致性视图会记录当前事务开始时已经提交的数据版本。

当执行查询操作时，MySQL 会根据事务的一致性视图来决定可见的数据版本。只有那些在事务开始之前已经提交的数据版本才是可见的，未提交的数据或在事务开始后修改的数据则对当前事务不可见。

像不加锁的 select 操作就是快照读，即不加锁的非阻塞读。

快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本。

**注意：快照读的前提是隔离级别不是串行级别，在串行级别下，事务之间完全串行执行，快照读会退化为当前读**

MVCC 主要就是为了实现读-写冲突不加锁，而这个读指的就是快照读，是乐观锁的实现。

‍

‍

### 实现简单理解

参考[MySQL中MVCC的正确打开方式（源码佐证）_mysql mvcc怎么开启-CSDN博客](https://blog.csdn.net/Waves___/article/details/105295060)

‍

①每次对记录进行改动，都会记录一条`undo日志`​，每条`undo日志`​也都有一个`roll_pointer`​属性（`INSERT`​操作对应的`undo日志`​没有该属性，因为该记录并没有更早的版本），可以将这些`undo日志`​都连起来，串成一个链表。所有的版本都会被`roll_pointer`​属性连接成一个链表，我们把这个链表称之为`版本链`​，版本链的头节点就是当前记录最新的值。另外，每个版本中还包含生成该版本时对应的`事务id`​

‍

②ReadView：需要判断一下版本链中的哪个版本是当前事务可见的。

* ​`m_ids`​：表示在生成`ReadView`​时当前系统中活跃的读写事务的`事务id`​列表。
* ​`min_trx_id`​：表示在生成`ReadView`​时当前系统中活跃的读写事务中最小的`事务id`​，也就是`m_ids`​中的最小值。
* ​`max_trx_id`​：表示生成`ReadView`​时系统中应该分配给下一个事务的`id`​值。
* ​`creator_trx_id`​：表示生成该`ReadView`​的事务的`事务id`​。

‍

③有了这个`ReadView`​，这样在访问某条记录时，只需要按照下边的步骤判断记录的某个版本是否可见：

* 如果被访问版本的`trx_id`​属性值与`ReadView`​中的`creator_trx_id`​值相同，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。
* 如果被访问版本的`trx_id`​属性值小于`ReadView`​中的`min_trx_id`​值，表明生成该版本的事务在当前事务生成`ReadView`​前已经提交，所以该版本可以被当前事务访问。
* 如果被访问版本的`trx_id`​属性值大于或等于`ReadView`​中的`max_trx_id`​值，表明生成该版本的事务在当前事务生成`ReadView`​后才开启，所以该版本不可以被当前事务访问。
* 如果被访问版本的`trx_id`​属性值在`ReadView`​的`min_trx_id`​和`max_trx_id`​**之间**，那就需要判断一下`trx_id`​属性值是不是在`m_ids`​列表中，如果在，说明创建`ReadView`​时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建`ReadView`​时生成该版本的事务已经被提交，该版本可以被访问。

如果某个版本的数据对当前事务不可见的话，那就顺着版本链找到下一个版本的数据，继续按照上边的步骤判断可见性，依此类推，直到版本链中的最后一个版本。如果最后一个版本也不可见的话，那么就意味着该条记录对该事务完全不可见，查询结果就不包含该记录。

‍

‍

## 脏页/干净页

‍

**脏页**：当内存数据页和磁盘数据页内容不一致的时候，称内存页为“脏页”

**干净页**：内存数据写入磁盘后，内存和磁盘数据一致了，称内存页为“干净页”

 平时很快的更新操作，都是在写内存和日志，并不会马上同步到磁盘，这时内存数据页和磁盘数据页内容不一致，我们称内存数据页为：“脏页”

 一条SQL语句，正常执行的时候很快，偶尔很慢，这时就可能是在将脏页同步到磁盘页中

‍

### 什么时候会引起将脏页同步到磁盘中？

1. 当redo log写满

    > redo log 写满时，系统就会停止所有的更新操作，将更新的这部分日志对应的脏页同步到磁盘中，此时所有的更新操作全部停止，写的性能变为0，必须待刷出一部分脏页后才能更新，这时就会导致sql语句 执行很慢
    >
2. 内存不足

    > 需要将一部分数据页淘汰掉，如果淘汰的是脏页，则需要先将脏页同步到磁盘,空出来的给别的数据页使用。
    >
3. MySQL认为系统“空闲”
4. MySQL关闭

    > MySQL 会把内存的脏页都同步到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。
    >

‍

### 刷出脏页会造成的影响

1. 如果是redo log写满了  
    尽量要避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都都会停止。此时写的性能变为0。必须待刷一部分脏页后才能更新,这时就会导致 sql语句 执行的很慢
2. 内存不够用了  
    常态，很正常！！。。。。。

‍

### 日志

1. redo log （重做日志）
2. undo log（回滚日志）
3. bin log（二进制日志）
4. error log（错误日志）
5. slow query log（慢查询日志）
6. general log（一般查询日志）
7. relay log（中继日志）

> 其中，redolog，undolog，binlog与事务息息相关

‍

#### redo log

> 重做日志

**作用：**

确保事务的持久性。redo日志记录事务执行后的状态，用来恢复未写入data file的已成功事务更新的数据。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启[mysql](https://www.2cto.com/database/MySQL/)服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。

**内容：**

物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。

**什么时候产生：**

事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。

**什么时候释放：**

当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。

**对应的物理文件：**

默认情况下，对应的物理文件位于[数据库](https://www.2cto.com/database/)的data目录下的ib_logfile1、ib_logfile2 ……

innodb_log_group_home_dir 指定日志文件组所在的路径，默认./ ，表示在数据库的数据目录下。

innodb_log_files_in_group 指定重做日志文件组中文件的数量，默认2

‍

**关于文件的大小和数量，由以下两个参数配置：**

innodb_log_file_size 重做日志文件的大小。

innodb_mirrored_log_groups 指定了日志镜像文件组的数量，默认1

**其他：**

很重要一点，redo log是什么时候写盘的？前面说了是在事物开始之后逐步写盘的。

之所以说重做日志是在事务开始之后逐步写入重做日志文件，而不一定是事务提交才写入重做日志缓存，原因就是，重做日志有一个缓存区Innodb_log_buffer，Innodb_log_buffer的默认大小为8M(这里设置的16M),Innodb存储引擎先将重做日志写入innodb_log_buffer中。

‍

然后会通过以下三种方式将innodb日志缓冲区的日志刷新到磁盘

1> Master Thread 每秒一次执行刷新Innodb_log_buffer到重做日志文件。

2> 每个事务提交时会将重做日志刷新到重做日志文件。

3> 当重做日志缓存可用空间 少于一半时，重做日志缓存被刷新到重做日志文件

由此可以看出，重做日志通过不止一种方式写入到磁盘，尤其是对于第一种方式，Innodb_log_buffer到重做日志文件是Master Thread线程的定时任务。

因此重做日志的写盘，并不一定是随着事务的提交才写入重做日志文件的，而是随着事务的开始，逐步开始的。

另外引用《MySQL技术内幕 Innodb 存储引擎》（page37）上的原话：

即使某个事务还没有提交，Innodb存储引擎仍然每秒会将重做日志缓存刷新到重做日志文件。

这一点是必须要知道的，因为这可以很好地解释再大的事务的提交（commit）的时间也是很短暂的。

‍

‍

#### undo log

> 回滚日志

**作用：**

保证数据的原子性，保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读

**内容：**

逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。

**什么时候产生：**

事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性

**什么时候释放：**

当事务提交之后，undo log并不能立马被删除，而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。

**对应的物理文件：**

MySQL5.6之前，undo表空间位于共享表空间的回滚段中，共享表空间的默认的名称是ibdata，位于数据文件目录中。

MySQL5.6之后，undo表空间可以配置成独立的文件，但是提前需要在配置文件中配置，完成数据库初始化后生效且不可改变undo log文件的个数

如果初始化数据库之前没有进行相关配置，那么就无法配置成独立的表空间了。

**关于MySQL5.7之后的独立undo 表空间配置参数如下：**

innodb_undo_directory = /data/undospace/ –undo独立表空间的存放目录 innodb_undo_logs = 128 –回滚段为128KB innodb_undo_tablespaces = 4 –指定有4个undo log文件

如果undo使用的共享表空间，这个共享表空间中又不仅仅是存储了undo的信息，共享表空间的默认为与MySQL的数据目录下面，其属性由参数innodb_data_file_path配置。

‍

**其他：**

undo是在事务开始之前保存的被修改数据的一个版本，产生undo日志的时候，同样会伴随类似于保护事务持久化机制的redolog的产生。

默认情况下undo文件是保持在共享表空间的，也即ibdatafile文件中，当数据库中发生一些大的事务性操作的时候，要生成大量的undo信息，全部保存在共享表空间中的。

因此共享表空间可能会变的很大，默认情况下，也就是undo 日志使用共享表空间的时候，被“撑大”的共享表空间是不会也不能自动收缩的。

因此，mysql5.7之后的“独立undo 表空间”的配置就显得很有必要了。

‍

#### binlog

> 二进制日志

**作用：**

用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。

用于数据库的基于时间点的还原。

**内容：**

逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。

但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息，也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。

在使用mysqlbinlog解析binlog之后一些都会真相大白。

因此可以基于binlog做到类似于oracle的闪回功能，其实都是依赖于binlog中的日志记录。

**什么时候产生：**

事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。

这里与redo log很明显的差异就是redo log并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘。

因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。

这是因为binlog是在事务提交的时候一次性写入的造成的，这些可以通过测试验证。

**什么时候释放：**

binlog的默认是保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。

‍

**对应的物理文件：**

配置文件的路径为log_bin_basename，binlog日志文件按照指定大小，当日志文件达到指定的最大的大小之后，进行滚动更新，生成新的日志文件。

对于每个binlog日志文件，通过一个统一的index文件来组织。

**其他：**

二进制日志的作用之一是还原数据库的，这与redo log很类似，很多人混淆过，但是两者有本质的不同

**作用不同**：redo log是保证事务的持久性的，是事务层面的，binlog作为还原的功能，是数据库层面的（当然也可以精确到事务层面的），虽然都有还原的意思，但是其保护数据的层次是不一样的。

**内容不同**：redo log是物理日志，是数据页面的修改之后的物理记录，binlog是逻辑日志，可以简单认为记录的就是sql语句

另外，两者日志产生的时间，可以释放的时间，在可释放的情况下清理机制，都是完全不同的。

恢复数据时候的效率，基于物理日志的redo log恢复数据的效率要高于语句逻辑日志的binlog

关于事务提交时，redo log和binlog的写入顺序，为了保证主从复制时候的主从一致（当然也包括使用binlog进行基于时间点还原的情况），是要严格一致的，MySQL通过两阶段提交过程来完成事务的一致性的，也即redo log和binlog的一致性的，理论上是先写redo log，再写binlog，两个日志都提交成功（刷入磁盘），事务才算真正的完成。

‍

#### errorlog

> 错误日志

错误日志记录着mysqld启动和停止,以及服务器在运行过程中发生的错误的相关信息。在默认情况下，系统记录错误日志的功能是关闭的，错误信息被输出到标准错误输出。  
　　指定日志路径两种方法:  
　　　　> 编辑my.cnf 写入 log-error=[path]  
　　　　> 通过命令参数错误日志 mysqld_safe –user=mysql –log-error=[path] &

显示错误日志的命令（如下图所示）

‍

‍

#### slow query log

> 慢查询日志

慢日志记录执行时间过长和没有使用索引的查询语句，报错select、update、delete以及insert语句，慢日志只会记录执行成功的语句。

‍

查看慢查询时间：

```sql
　　 show variables like “long_query_time”;默认10s
```

‍

查看慢查询配置情况：

```sql
　　 show status like “%slow_queries%”;
```

‍

查看慢查询日志路径：

```sql
　　 show variables like “%slow%”;
```

‍

开启慢日志

```sql
    set global slow_query_log = 1
```

‍

查看已经开启：

```sql
    show variables like "%slow_query_log%";
```

‍

#### general log

> 普通查询日志

记录了服务器接收到的每一个查询或是命令，无论这些查询或是命令是否正确甚至是否包含语法错误，general log 都会将其记录下来 ，记录的格式为 {Time ，Id ，Command，Argument }。也正因为mysql服务器需要不断地记录日志，开启General log会产生不小的系统开销。 因此，Mysql默认是把General log关闭的。

‍

查看日志的存放方式：show variables like ‘log_output’;

如果设置mysql> set global log_output=’table’ 的话，则日志结果会记录到名为gengera_log的表中，这表的默认引擎都是CSV  
　　如果设置表数据到文件set global log_output=file;  
　　设置general log的日志文件路径：  
　　　　set global general_log_file=’/tmp/general.log’;  
　　　　开启general log： set global general_log=on;  
　　　　关闭general log： set global general_log=off;

‍

然后再用：show global variables like ‘general_log’

‍

#### relay log

> 中继日志

在从节点，用于主从复制的日志

‍

## 体系架构(高阶)

‍

‍

‍

### 整体架构

‍

体系结构详解：

* 第一层：网络连接层

  * 一些客户端和链接服务，包含本地 Socket 通信和大多数基于客户端/服务端工具实现的 TCP/IP 通信，主要完成一些类似于连接处理、授权认证、及相关的安全方案
  * 在该层上引入了**连接池** Connection Pool 的概念，管理缓冲用户连接，线程处理等需要缓存的需求
  * 在该层上实现基于 SSL 的安全链接，服务器也会为安全接入的每个客户端验证它所具有的操作权限
* 第二层：核心服务层

  * 查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，所有的内置函数（日期、数学、加密函数等）

    * Management Serveices & Utilities：系统管理和控制工具，备份、安全、复制、集群等
    * SQL Interface：接受用户的 SQL 命令，并且返回用户需要查询的结果
    * Parser：SQL 语句分析器
    * Optimizer：查询优化器
    * Caches & Buffers：查询缓存，服务器会查询内部的缓存，如果缓存空间足够大，可以在大量读操作的环境中提升系统性能
  * 所有**跨存储引擎的功能**在这一层实现，如存储过程、触发器、视图等
  * 在该层服务器会解析查询并创建相应的内部解析树，并对其完成相应的优化如确定表的查询顺序，是否利用索引等， 最后生成相应的执行操作
  * MySQL 中服务器层不管理事务，**事务是由存储引擎实现的**
* 第三层：存储引擎层

  * Pluggable Storage Engines：存储引擎接口，MySQL 区别于其他数据库的重要特点就是其存储引擎的架构模式是插件式的（存储引擎是基于表的，而不是数据库）
  * 存储引擎**真正的负责了 MySQL 中数据的存储和提取**，服务器通过 API 和存储引擎进行通信
  * 不同的存储引擎具有不同的功能，共用一个 Server 层，可以根据开发的需要，来选取合适的存储引擎
* 第四层：系统文件层

  * 数据存储层，主要是将数据存储在文件系统之上，并完成与存储引擎的交互
  * File System：文件系统，保存配置文件、数据文件、日志文件、错误文件、二进制文件等

‍

### 连接状态

客户端如果长时间没有操作，连接器就会自动断开，时间是由参数 wait_timeout 控制的，默认值是 8 小时。如果在连接被断开之后，客户端**再次发送请求**的话，就会收到一个错误提醒：`Lost connection to MySQL server during query`​

数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接；短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个

为了减少连接的创建，推荐使用长连接，但是**过多的长连接会造成 OOM**，解决方案：

* 定期断开长连接，使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连

  ```mysql
  KILL CONNECTION id
  ```
* MySQL 5.7 版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源，这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态

SHOW PROCESSLIST：查看当前 MySQL 在进行的线程，可以实时地查看 SQL 的执行情况，其中的 Command 列显示为 Sleep 的这一行，就表示现在系统里面有一个空闲连接

|参数|含义|
| ---------| ----------------------------------------------------------------------------------------------------------------------------|
|ID|用户登录 mysql 时系统分配的 connection_id，可以使用函数 connection_id() 查看|
|User|显示当前用户，如果不是 root，这个命令就只显示用户权限范围的 sql 语句|
|Host|显示这个语句是从哪个 ip 的哪个端口上发的，可以用来跟踪出现问题语句的用户|
|db|显示这个进程目前连接的是哪个数据库|
|Command|显示当前连接的执行的命令，一般取值为休眠 Sleep、查询 Query、连接 Connect 等|
|Time|显示这个状态持续的时间，单位是秒|
|State|显示使用当前连接的 sql 语句的状态，以查询为例，需要经过 copying to tmp table、sorting result、sending data等状态才可以完成|
|Info|显示执行的 sql 语句，是判断问题语句的一个重要依据|

**Sending data 状态**表示 MySQL 线程开始访问数据行并把结果返回给客户端，而不仅仅只是返回给客户端，是处于执行器过程中的任意阶段。由于在 Sending data 状态下，MySQL 线程需要做大量磁盘读取操作，所以是整个查询中耗时最长的状态

‍

### 执行流程

#### 查询缓存

##### 工作流程

当执行完全相同的 SQL 语句的时候，服务器就会直接从缓存中读取结果，当数据被修改，之前的缓存会失效，修改比较频繁的表不适合做查询缓存

查询过程：

1. 客户端发送一条查询给服务器
2. 服务器先会检查查询缓存，如果命中了缓存，则立即返回存储在缓存中的结果（一般是 K-V 键值对），否则进入下一阶段
3. 分析器进行 SQL 分析，再由优化器生成对应的执行计划
4. 执行器根据优化器生成的执行计划，调用存储引擎的 API 来执行查询
5. 将结果返回给客户端

大多数情况下不建议使用查询缓存，因为查询缓存往往弊大于利

* 查询缓存的**失效非常频繁**，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能费力地把结果存起来，还没使用就被一个更新全清空了，对于更新压力大的数据库来说，查询缓存的命中率会非常低
* 除非业务就是有一张静态表，很长时间才会更新一次，比如一个系统配置表，那这张表上的查询才适合使用查询缓存

---

##### 缓存配置

1. 查看当前 MySQL 数据库是否支持查询缓存：

    ```mysql
    SHOW VARIABLES LIKE 'have_query_cache';	-- YES
    ```
2. 查看当前 MySQL 是否开启了查询缓存：

    ```mysql
    SHOW VARIABLES LIKE 'query_cache_type';	-- OFF
    ```

    参数说明：

    * OFF 或 0：查询缓存功能关闭
    * ON 或 1：查询缓存功能打开，查询结果符合缓存条件即会缓存，否则不予缓存；可以显式指定 SQL_NO_CACHE 不予缓存
    * DEMAND 或 2：查询缓存功能按需进行，显式指定 SQL_CACHE 的 SELECT 语句才缓存，其它不予缓存

      ```mysql
      SELECT SQL_CACHE id, name FROM customer; -- SQL_CACHE:查询结果可缓存
      SELECT SQL_NO_CACHE id, name FROM customer;-- SQL_NO_CACHE:不使用查询缓存
      ```
3. 查看查询缓存的占用大小：

    ```mysql
    SHOW VARIABLES LIKE 'query_cache_size';-- 单位是字节 1048576 / 1024 = 1024 = 1KB
    ```
4. 查看查询缓存的状态变量：

    ```mysql
    SHOW STATUS LIKE 'Qcache%';
    ```

‍

|参数|含义|
| -------------------------| ------------------------------------------------------------------|
|Qcache_free_blocks|查询缓存中的可用内存块数|
|Qcache_free_memory|查询缓存的可用内存量|
|Qcache_hits|查询缓存命中数|
|Qcache_inserts|添加到查询缓存的查询数|
|Qcache_lowmen_prunes|由于内存不足而从查询缓存中删除的查询数|
|Qcache_not_cached|非缓存查询的数量（由于 query_cache_type 设置而无法缓存或未缓存）|
|Qcache_queries_in_cache|查询缓存中注册的查询数|
|Qcache_total_blocks|查询缓存中的块总数|

‍

1. 配置 my.cnf：

    ```bash
    sudo chmod 666 /etc/mysql/my.cnf
    vim my.cnf
    # mysqld中配置缓存
    query_cache_type=1
    ```

    重启服务既可生效，执行 SQL 语句进行验证 ，执行一条比较耗时的 SQL 语句，然后再多执行几次，查看后面几次的执行时间；获取通过查看查询缓存的缓存命中数，来判定是否走查询缓存

---

##### 缓存失效

查询缓存失效的情况：

* SQL 语句不一致，要想命中查询缓存，查询的 SQL 语句必须一致，因为**缓存中 key 是查询的语句**，value 是查询结构

  ```mysql
  select count(*) from tb_item;
  Select count(*) from tb_item;	-- 不走缓存，首字母不一致
  ```
* 当查询语句中有一些不确定查询时，则不会缓存，比如：now()、current_date()、curdate()、curtime()、rand()、uuid()、user()、database()

  ```mysql
  SELECT * FROM tb_item WHERE updatetime < NOW() LIMIT 1;
  SELECT USER();
  SELECT DATABASE();
  ```
* 不使用任何表查询语句：

  ```mysql
  SELECT 'A';
  ```
* 查询 mysql、information_schema、performance_schema 等系统表时，不走查询缓存：

  ```mysql
  SELECT * FROM information_schema.engines;
  ```
* 在**跨存储引擎**的存储过程、触发器或存储函数的主体内执行的查询，缓存失效
* 如果表更改，则使用该表的**所有高速缓存查询都将变为无效**并从高速缓存中删除，包括使用 MERGE 映射到已更改表的表的查询，比如：INSERT、UPDATE、DELETE、ALTER TABLE、DROP TABLE、DROP DATABASE

---

#### 分析器

没有命中查询缓存，就开始了 SQL 的真正执行，分析器会对 SQL 语句做解析

```sql
SELECT * FROM t WHERE id = 1;
```

解析器：处理语法和解析查询，生成一课对应的解析树

* 先做**词法分析**，输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么代表什么。从输入的 select 这个关键字识别出来这是一个查询语句；把字符串 t 识别成 表名 t，把字符串 id 识别成列 id
* 然后做**语法分析**，根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。如果语句不对，就会收到 `You have an error in your SQL syntax`​ 的错误提醒

预处理器：进一步检查解析树的合法性，比如数据表和数据列是否存在、别名是否有歧义等

---

‍

#### 优化器

##### 成本分析

优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序

* 根据搜索条件找出所有可能的使用的索引
* 成本分析，执行成本由 I/O 成本和 CPU 成本组成，计算全表扫描和使用不同索引执行 SQL 的代价
* 找到一个最优的执行方案，用最小的代价去执行语句

在数据库里面，扫描行数是影响执行代价的因素之一，扫描的行数越少意味着访问磁盘的次数越少，消耗的 CPU 资源越少，优化器还会结合是否使用临时表、是否排序等因素进行综合判断

---

##### 统计数据

MySQL 中保存着两种统计数据：

* innodb_table_stats 存储了表的统计数据，每一条记录对应着一个表的统计数据
* innodb_index_stats 存储了索引的统计数据，每一条记录对应着一个索引的一个统计项的数据

MySQL 在真正执行语句之前，并不能精确地知道满足条件的记录有多少条，只能根据统计信息来估算记录，统计信息就是索引的区分度，一个索引上不同的值的个数（比如性别只能是男女，就是 2 ），称之为基数（cardinality），**基数越大说明区分度越好**

通过**采样统计**来获取基数，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数

在 MySQL 中，有两种存储统计数据的方式，可以通过设置参数 `innodb_stats_persistent`​ 的值来选择：

* ON：表示统计信息会持久化存储（默认），采样页数 N 默认为 20，可以通过 `innodb_stats_persistent_sample_pages`​ 指定，页数越多统计的数据越准确，但消耗的资源更大
* OFF：表示统计信息只存储在内存，采样页数 N 默认为 8，也可以通过系统变量设置（不推荐，每次重新计算浪费资源）

数据表是会持续更新的，两种统计信息的更新方式：

* 设置 `innodb_stats_auto_recalc`​ 为 1，当发生变动的记录数量超过表大小的 10% 时，自动触发重新计算，不过是**异步进行**
* 调用 `ANALYZE TABLE t`​ 手动更新统计信息，只对信息做**重新统计**（不是重建表），没有修改数据，这个过程中加了 MDL 读锁并且是同步进行，所以会暂时阻塞系统

**EXPLAIN 执行计划在优化器阶段生成**，如果 explain 的结果预估的 rows 值跟实际情况差距比较大，可以执行 analyze 命令重新修正信息

---

##### 错选索引

采样统计本身是估算数据，或者 SQL 语句中的字段选择有问题时，可能导致 MySQL 没有选择正确的执行索引

解决方法：

* 采用 force index 强行选择一个索引

  ```sql
  SELECT * FROM user FORCE INDEX(name) WHERE NAME='seazean';
  ```
* 可以考虑修改 SQL 语句，引导 MySQL 使用期望的索引
* 新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引

‍

#### 执行器

开始执行的时候，要先判断一下当前连接对表有没有**执行查询的权限**，如果没有就会返回没有权限的错误，在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。如果有权限，就打开表继续执行，执行器就会根据表的引擎定义，去使用这个引擎提供的接口

---

#### 引擎层

Server 层和存储引擎层的交互是**以记录为单位的**，存储引擎会将单条记录返回给 Server 层做进一步处理，并不是直接返回所有的记录

工作流程：

* 首先根据二级索引选择扫描范围，获取第一条符合二级索引条件的记录，进行回表查询，将聚簇索引的记录返回 Server 层，由 Server 判断记录是否符合要求
* 然后在二级索引上继续扫描下一个符合条件的记录

推荐阅读：[https://mp.weixin.qq.com/s/YZ-LckObephrP1f15mzHpA](https://mp.weixin.qq.com/s/YZ-LckObephrP1f15mzHpA)

---

### 终止流程

#### 终止语句

终止线程中正在执行的语句：

```mysql
KILL QUERY thread_id
```

KILL 不是马上终止的意思，而是告诉执行线程这条语句已经不需要继续执行，可以开始执行停止的逻辑（类似于打断）。因为对表做增删改查操作，会在表上加 MDL 读锁，如果线程被 KILL 时就直接终止，那这个 MDL 读锁就没机会被释放了

命令 `KILL QUERYthread_id_A`​ 的执行流程：

* 把 session A 的运行状态改成 THD::KILL_QUERY（将变量 killed 赋值为 THD::KILL_QUERY）
* 给 session A 的执行线程发一个信号，让 session A 来处理这个 THD::KILL_QUERY 状态

会话处于等待状态（锁阻塞），必须满足是一个可以被唤醒的等待，必须有机会去**判断线程的状态**，如果不满足就会造成 KILL 失败

典型场景：innodb_thread_concurrency 为 2，代表并发线程上限数设置为 2

* session A 执行事务，session B 执行事务，达到线程上限；此时 session C 执行事务会阻塞等待，session D 执行 kill query C 无效
* C 的逻辑是每 10 毫秒判断是否可以进入 InnoDB 执行，如果不行就调用 nanosleep 函数进入 sleep 状态，没有去判断线程状态

补充：执行 Ctrl+C 的时候，是 MySQL 客户端另外启动一个连接，然后发送一个 KILL QUERY 命令

---

#### 终止连接

断开线程的连接：

```mysql
KILL CONNECTION id
```

断开连接后执行 SHOW PROCESSLIST 命令，如果这条语句的 Command 列显示 Killed，代表线程的状态是 KILL_CONNECTION，说明这个线程有语句正在执行，当前状态是停止语句执行中，终止逻辑耗时较长

* 超大事务执行期间被 KILL，这时回滚操作需要对事务执行期间生成的所有新数据版本做回收操作，耗时很长
* 大查询回滚，如果查询过程中生成了比较大的临时文件，删除临时文件可能需要等待 IO 资源，导致耗时较长
* DDL 命令执行到最后阶段被 KILL，需要删除中间过程的临时文件，也可能受 IO 资源影响耗时较久

总结：KILL CONNECTION 本质上只是把客户端的 SQL 连接断开，后面的终止流程还是要走 KILL QUERY

一个事务被 KILL 之后，持续处于回滚状态，不应该强行重启整个 MySQL 进程，应该等待事务自己执行完成，因为重启后依然继续做回滚操作的逻辑

---

### 常用工具

#### mysql

mysql 不是指 mysql 服务，而是指 mysql 的客户端工具

```bash
mysql [options] [database]
```

* -u --user=name：指定用户名
* -p --password[=name]：指定密码
* -h --host=name：指定服务器IP或域名
* -P --port=#：指定连接端口
* -e --execute=name：执行SQL语句并退出，在控制台执行SQL语句，而不用连接到数据库执行

示例：

```bash
mysql -h 127.0.0.1 -P 3306 -u root -p
mysql -uroot -p2143 db01 -e "select * from tb_book";
```

---

#### admin

mysqladmin 是一个执行管理操作的客户端程序，用来检查服务器的配置和当前状态、创建并删除数据库等

通过 `mysqladmin --help`​ 指令查看帮助文档

```bash
mysqladmin -uroot -p2143 create 'test01';
```

---

#### binlog

服务器生成的日志文件以二进制格式保存，如果需要检查这些文本，就要使用 mysqlbinlog 日志管理工具

```bash
mysqlbinlog [options]  log-files1 log-files2 ...
```

* -d --database=name：指定数据库名称，只列出指定的数据库相关操作
* -o --offset=#：忽略掉日志中的前 n 行命令。
* -r --result-file=name：将输出的文本格式日志输出到指定文件。
* -s --short-form：显示简单格式，省略掉一些信息。
* --start-datatime=date1 --stop-datetime=date2：指定日期间隔内的所有日志
* --start-position=pos1 --stop-position=pos2：指定位置间隔内的所有日志

---

#### dump

##### 命令介绍

mysqldump 客户端工具用来备份数据库或在不同数据库之间进行数据迁移，备份内容包含创建表，及插入表的 SQL 语句

```bash
mysqldump [options] db_name [tables]
mysqldump [options] --database/-B db1 [db2 db3...]
mysqldump [options] --all-databases/-A
```

连接选项：

* -u --user=name：指定用户名
* -p --password[=name]：指定密码
* -h --host=name：指定服务器 IP 或域名
* -P --port=#：指定连接端口

输出内容选项：

* --add-drop-database：在每个数据库创建语句前加上 Drop database 语句
* --add-drop-table：在每个表创建语句前加上 Drop table 语句 , 默认开启，不开启 (--skip-add-drop-table)
* -n --no-create-db：不包含数据库的创建语句
* -t --no-create-info：不包含数据表的创建语句
* -d --no-data：不包含数据
* -T, --tab=name：自动生成两个文件：一个 .sql 文件，创建表结构的语句；一个 .txt 文件，数据文件，相当于 select into outfile

示例：

```bash
mysqldump -uroot -p2143 db01 tb_book --add-drop-database --add-drop-table > a
mysqldump -uroot -p2143 -T /tmp test city
```

---

##### 数据备份

命令行方式：

* 备份命令：mysqldump -u root -p 数据库名称 > 文件保存路径
* 恢复

  1. 登录MySQL数据库：`mysql -u root p`​
  2. 删除已经备份的数据库
  3. 重新创建与备份数据库名称相同的数据库
  4. 使用该数据库
  5. 导入文件执行：`source 备份文件全路径`​

更多方式参考：[https://time.geekbang.org/column/article/81925](https://time.geekbang.org/column/article/81925)

‍

#### import

mysqlimport 是客户端数据导入工具，用来导入mysqldump 加 -T 参数后导出的文本文件

```bash
mysqlimport [options]  db_name  textfile1  [textfile2...]
```

示例：

```bash
mysqlimport -uroot -p2143 test /tmp/city.txt
```

导入 sql 文件，可以使用 MySQL 中的 source 指令 :

```mysql
source 文件全路径
```

---

#### show

mysqlshow 客户端对象查找工具，用来很快地查找存在哪些数据库、数据库中的表、表中的列或者索引

```bash
mysqlshow [options] [db_name [table_name [col_name]]]
```

* --count：显示数据库及表的统计信息（数据库，表 均可以不指定）
* -i：显示指定数据库或者指定表的状态信息

示例：

```bash
#查询每个数据库的表的数量及表中记录的数量
mysqlshow -uroot -p1234 --count
#查询test库中每个表中的字段书，及行数
mysqlshow -uroot -p1234 test --count
#查询test库中book表的详细情况
mysqlshow -uroot -p1234 test book --count
```

‍

‍

‍

## 系统优化(高阶)

‍

### 表优化

‍

#### 分区表

##### 基本介绍

分区表是将大表的数据按分区字段分成许多小的子集，建立一个以 ftime 年份为分区的表：

```mysql
CREATE TABLE `t` (
    `ftime` datetime NOT NULL,
    `c` int(11) DEFAULT NULL,
    KEY (`ftime`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1
PARTITION BY RANGE (YEAR(ftime))
(PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB,
 PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB,
 PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB,
 PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB);
INSERT INTO t VALUES('2017-4-1',1),('2018-4-1',1);-- 这两行记录分别落在 p_2018 和 p_2019 这两个分区上
```

这个表包含了一个.frm 文件和 4 个.ibd 文件，每个分区对应一个.ibd 文件

* 对于引擎层来说，这是 4 个表，针对每个分区表的操作不会相互影响
* 对于 Server 层来说，这是 1 个表

---

##### 分区策略

打开表行为：第一次访问一个分区表时，MySQL 需要**把所有的分区都访问一遍**，如果分区表的数量很多，超过了 open_files_limit 参数（默认值 1024），那么就会在访问这个表时打开所有的文件，导致打开表文件的个数超过了上限而报错

通用分区策略：MyISAM 分区表使用的分区策略，每次访问分区都由 Server 层控制，在文件管理、表管理的实现上很粗糙，因此有比较严重的性能问题

本地分区策略：从 MySQL 5.7.9 开始，InnoDB 引擎内部自己管理打开分区的行为，InnoDB 引擎打开文件超过 innodb_open_files 时就会**关掉一些之前打开的文件**，所以即使分区个数大于 open_files_limit，也不会报错

从 MySQL 8.0 版本开始，就不允许创建 MyISAM 分区表，只允许创建已经实现了本地分区策略的引擎，目前只有 InnoDB 和 NDB 这两个引擎支持了本地分区策略

---

##### Server 层

从 Server 层看一个分区表就只是一个表

* Session A：

  ```mysql
  SELECT * FROM t WHERE ftime = '2018-4-1';
  ```
* Session B：

  ```mysql
  ALTER TABLE t TRUNCATE PARTITION p_2017; -- blocked
  ```

现象：Session B 只操作 p_2017 分区，但是由于 Session A 持有整个表 t 的 MDL 读锁，就导致 B 的 ALTER 语句获取 MDL 写锁阻塞

分区表的特点：

* 第一次访问的时候需要访问所有分区
* 在 Server 层认为这是同一张表，因此**所有分区共用同一个 MDL 锁**
* 在引擎层认为这是不同的表，因此 MDL 锁之后的执行过程，会根据分区表规则，只访问需要的分区

---

##### 应用场景

分区表的优点：

* 对业务透明，相对于用户分表来说，使用分区表的业务代码更简洁
* 分区表可以很方便的清理历史数据。按照时间分区的分区表，就可以直接通过 `alter table t drop partition`​ 这个语法直接删除分区文件，从而删掉过期的历史数据，与使用 drop 语句删除数据相比，优势是速度快、对系统影响小

使用分区表，不建议创建太多的分区，注意事项：

* 分区并不是越细越好，单表或者单分区的数据一千万行，只要没有特别大的索引，对于现在的硬件能力来说都已经是小表
* 分区不要提前预留太多，在使用之前预先创建即可。比如是按月分区，每年年底时再把下一年度的 12 个新分区创建上即可，并且对于没有数据的历史分区，要及时的 drop 掉

参考文档：[https://time.geekbang.org/column/article/82560](https://time.geekbang.org/column/article/82560)

---

#### 临时表

##### 基本介绍

临时表分为内部临时表和用户临时表

* 内部临时表：系统执行 SQL 语句优化时产生的表，例如 Join 连接查询、去重查询等
* 用户临时表：用户主动创建的临时表

  ```mysql
  CREATE TEMPORARY TABLE temp_t like table_1;
  ```

临时表可以是内存表，也可以是磁盘表（多表操作 → 嵌套查询章节提及）

* 内存表指的是使用 Memory 引擎的表，建立哈希索引，建表语法是 `create table … engine=memory`​，这种表的数据都保存在内存里，系统重启时会被清空，但是表结构还在
* 磁盘表是使用 InnoDB 引擎或者 MyISAM 引擎的临时表，建立 B+ 树索引，写数据的时候是写到磁盘上的

临时表的特点：

* 一个临时表只能被创建它的 session 访问，对其他线程不可见，所以不同 session 的临时表是**可以重名**的
* 临时表可以与普通表同名，会话内有同名的临时表和普通表时，执行 show create 语句以及增删改查语句访问的都是临时表
* show tables 命令不显示临时表
* 数据库发生异常重启不需要担心数据删除问题，临时表会**自动回收**

---

##### 重名原理

执行创建临时表的 SQL：

```mysql
create temporary table temp_t(id int primary key)engine=innodb;
```

MySQL 给 InnoDB 表创建一个 frm 文件保存表结构定义，在 ibd 保存表数据。frm 文件放在临时文件目录下，文件名的后缀是 .frm，**前缀是** `#sql{进程 id}_{线程 id}_ 序列号`​，使用 `select @@tmpdir`​ 命令，来显示实例的临时文件目录

MySQL 维护数据表，除了物理磁盘上的文件外，内存里也有一套机制区别不同的表，每个表都对应一个 table_def_key

* 一个普通表的 table_def_key 的值是由 `库名 + 表名`​ 得到的，所以如果在同一个库下创建两个同名的普通表，创建第二个表的过程中就会发现 table_def_key 已经存在了
* 对于临时表，table_def_key 在 `库名 + 表名`​ 基础上，又加入了 `server_id + thread_id`​，所以不同线程之间，临时表可以重名

实现原理：每个线程都维护了自己的临时表链表，每次 session 内操作表时，先遍历链表，检查是否有这个名字的临时表，如果有就**优先操作临时表**，如果没有再操作普通表；在 session 结束时对链表里的每个临时表，执行 `DROP TEMPORARY TABLE + 表名`​ 操作

执行 rename table 语句无法修改临时表，因为会按照 `库名 / 表名.frm`​ 的规则去磁盘找文件，但是临时表文件名的规则是 `#sql{进程 id}_{线程 id}_ 序列号.frm`​，因此会报找不到文件名的错误

---

##### 主备复制

创建临时表的语句会传到备库执行，因此备库的同步线程就会创建这个临时表。主库在线程退出时会自动删除临时表，但备库同步线程是持续在运行的并不会退出，所以这时就需要在主库上再写一个 DROP TEMPORARY TABLE 传给备库执行

binlog 日志写入规则：

* binlog_format=row，跟临时表有关的语句就不会记录到 binlog
* binlog_format=statment/mixed，binlog 中才会记录临时表的操作，也就会记录 `DROP TEMPORARY TABLE`​ 这条命令

主库上不同的线程创建同名的临时表是不冲突的，但是备库只有一个执行线程，所以 MySQL 在记录 binlog 时会把主库执行这个语句的线程 id 写到 binlog 中，在备库的应用线程就可以获取执行每个语句的主库线程 id，并利用这个线程 id 来构造临时表的 table_def_key

* session A 的临时表 t1，在备库的 table_def_key 就是：`库名 + t1 +“M 的 serverid" + "session A 的 thread_id”`​
* session B 的临时表 t1，在备库的 table_def_key 就是 ：`库名 + t1 +"M 的 serverid" + "session B 的 thread_id"`​

MySQL 在记录 binlog 的时不论是 create table 还是 alter table 语句都是原样记录，但是如果执行 drop table，系统记录 binlog 就会被服务端改写

```mysql
DROP TABLE `t_normal` /* generated by server */
```

---

##### 跨库查询

分库分表系统的跨库查询使用临时表不用担心线程之间的重名冲突，分库分表就是要把一个逻辑上的大表分散到不同的数据库实例上

比如将一个大表 ht，按照字段 f，拆分成 1024 个分表，分布到 32 个数据库实例上，一般情况下都有一个中间层 proxy 解析 SQL 语句，通过分库规则通过分表规则（比如 N%1024）确定将这条语句路由到哪个分表做查询

```mysql
select v from ht where f=N;
```

如果这个表上还有另外一个索引 k，并且查询语句：

```mysql
select v from ht where k >= M order by t_modified desc limit 100;
```

查询条件里面没有用到分区字段 f，只能**到所有的分区**中去查找满足条件的所有行，然后统一做 order by 操作，两种方式：

* 在 proxy 层的进程代码中实现排序，拿到分库的数据以后，直接在内存中参与计算，但是对 proxy 端的压力比较大，很容易出现内存不够用和 CPU 瓶颈问题
* 把各个分库拿到的数据，汇总到一个 MySQL 实例的一个表中，然后在这个汇总实例上做逻辑操作，执行流程：

  * 在汇总库上创建一个临时表 temp_ht，表里包含三个字段 v、k、t_modified
  * 在各个分库执行：`select v,k,t_modified from ht_x where k >= M order by t_modified desc limit 100`​
  * 把分库执行的结果插入到 temp_ht 表中
  * 在临时表上执行：`select v from temp_ht order by t_modified desc limit 100`​

‍

‍

### 优化步骤

#### 执行频率

MySQL 客户端连接成功后，查询服务器状态信息：

```mysql
SHOW [SESSION|GLOBAL] STATUS LIKE '';
-- SESSION: 显示当前会话连接的统计结果，默认参数
-- GLOBAL: 显示自数据库上次启动至今的统计结果
```

* 查看 SQL 执行频率：

  ```mysql
  SHOW STATUS LIKE 'Com_____';
  ```

Com_xxx 表示每种语句执行的次数

* 查询 SQL 语句影响的行数：

```mysql
SHOW STATUS LIKE 'Innodb_rows_%';
```

Com_xxxx：这些参数对于所有存储引擎的表操作都会进行累计

Innodb_xxxx：这几个参数只是针对 InnoDB 存储引擎的，累加的算法也略有不同

|参数|含义|
| ----------------------| ----------------------------------------------------------------|
|Com_select|执行 SELECT 操作的次数，一次查询只累加 1|
|Com_insert|执行 INSERT 操作的次数，对于批量插入的 INSERT 操作，只累加一次|
|Com_update|执行 UPDATE 操作的次数|
|Com_delete|执行 DELETE 操作的次数|
|Innodb_rows_read|执行 SELECT 查询返回的行数|
|Innodb_rows_inserted|执行 INSERT 操作插入的行数|
|Innodb_rows_updated|执行 UPDATE 操作更新的行数|
|Innodb_rows_deleted|执行 DELETE 操作删除的行数|
|Connections|试图连接 MySQL 服务器的次数|
|Uptime|服务器工作时间|
|Slow_queries|慢查询的次数|

---

#### 定位低效

SQL 执行慢有两种情况：

* 偶尔慢：DB 在刷新脏页（学完事务就懂了）

  * redo log 写满了
  * 内存不够用，要从 LRU 链表中淘汰
  * MySQL 认为系统空闲的时候
  * MySQL 关闭时
* 一直慢的原因：索引没有设计好、SQL 语句没写好、MySQL 选错了索引

‍

通过以下两种方式定位执行效率较低的 SQL 语句

* 慢日志查询： 慢查询日志在查询结束以后才记录，执行效率出现问题时查询日志并不能定位问题  
  配置文件修改：修改 .cnf 文件 `vim /etc/mysql/my.cnf`​，重启 MySQL 服务器

  ```bash
  slow_query_log=ON
  slow_query_log_file=/usr/local/mysql/var/localhost-slow.log
  long_query_time=1	#记录超过long_query_time秒的SQL语句的日志
  log-queries-not-using-indexes = 1
  ```

  使用命令配置：

  ```mysql
  mysql> SET slow_query_log=ON;
  mysql> SET GLOBAL slow_query_log=ON;
  ```

  查看是否配置成功：

  ```mysql
  SHOW VARIABLES LIKE '%query%'
  ```
* SHOW PROCESSLIST：**实时查看**当前 MySQL 在进行的连接线程，包括线程的状态、是否锁表、SQL 的执行情况，同时对一些锁表操作进行优化

‍

‍

#### EXPLAIN

##### 执行计划

通过 EXPLAIN 命令获取执行 SQL 语句的信息，包括在 SELECT 语句执行过程中如何连接和连接的顺序，执行计划在优化器优化完成后、执行器之前生成，然后执行器会调用存储引擎检索数据

查询 SQL 语句的执行计划：

```mysql
EXPLAIN SELECT * FROM table_1 WHERE id = 1;
```

|字段|含义|
| ---------------| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|id|SELECT 的序列号|
|select_type|表示 SELECT 的类型|
|table|访问数据库中表名称，有时可能是简称或者临时表名称（<table_name>）|
|type|表示表的连接类型|
|possible_keys|表示查询时，可能使用的索引|
|key|表示实际使用的索引|
|key_len|索引字段的长度|
|ref|表示与索引列进行等值匹配的对象，常数、某个列、函数等，type 必须在（range, const] 之间，左闭右开|
|rows|扫描出的行数，表示 MySQL 根据表统计信息及索引选用情况，**估算**的找到所需的记录扫描的行数|
|filtered|条件过滤的行百分比，单表查询没意义，用于连接查询中对驱动表的扇出进行过滤，查询优化器预测所有扇出值满足剩余查询条件的百分比，相乘以后表示多表查询中还要对被驱动执行查询的次数|
|extra|执行情况的说明和描述|

MySQL **执行计划的局限**：

* 只是计划，不是执行 SQL 语句，可以随着底层优化器输入的更改而更改
* EXPLAIN 不会告诉显示关于触发器、存储过程的信息对查询的影响情况， 不考虑各种 Cache
* EXPLAIN 不能显示 MySQL 在执行查询时的动态，因为执行计划在执行**查询之前生成**
* EXPALIN 只能解释 SELECT 操作，其他操作要重写为 SELECT 后查看执行计划
* EXPLAIN PLAN 显示的是在解释语句时数据库将如何运行 SQL 语句，由于执行环境和 EXPLAIN PLAN 环境的不同，此计划可能与 SQL 语句**实际的执行计划不同**，部分统计信息是估算的，并非精确值

SHOW WARINGS：在使用 EXPALIN 命令后执行该语句，可以查询与执行计划相关的拓展信息，展示出 Level、Code、Message 三个字段，当 Code 为 1003 时，Message 字段展示的信息类似于将查询语句重写后的信息，但是不是等价，不能执行复制过来运行

...

‍

‍

# 实操

‍

## Bugfix

‍

### 编码问题

‍

#### 字符集编码设置

设置数据库表默认字符集编码

(降低了通用性,不建议)

‍

在my.ini中配置默认编码

```sql
character-set-server=utf8
```

---

* mysql有六处使用了字符集，分别为：

  * clinet、connection、database、results、server、system
* client是客户端使用的字符集
* connection是连接数据库的字符集设置类型，如果程序没有指明连接数据库使用的字符集类型，就按照服务器端默认的字符集设置
* database是数据服务器中某个库使用的字符集设定，如果建库时没有指明，将使用服务器安装时指定的字符集设置
* results是数据库给客户端返回时使用的字符集设定，如果没有指明，使用服务器默认的字符集
* server是服务器安装时指定的默认字符集设定
* system是数据库系统使用的字符集设定（utf-8不可修改）

  * ​`show variables like 'character%';`​
  * ​`set names gbk;`​临时修改当前cmd窗口和mysql的通信编码字符集
* 通过修改my.ini 修改字符集编码

  > 修改此文件时，先停止mysql服务，完成后重新启动
  >
  > 停止：`net stop mysql`​
  >
  > 启动：`net start mysql`​
  >

```ini
[mysql]
# 设置mysql客户端默认字符集
default-character-set=utf8 
[mysqld]
#设置3306端口
port = 3306 
# 设置mysql的安装目录
basedir=D:\mysql\mysql-5.7.27-winx64
# 设置mysql数据库的数据的存放目录
datadir=D:\mysql\data 
# 允许最大连接数
max_connections=200
# 服务端使用的字符集默认为8比特编码的latin1字符集
character-set-server=utf8
# 创建新表时将使用的默认存储引擎
default-storage-engine=INNODB
```

‍

‍

#### DOS乱码解决

‍

因为mysql的客户端编码的问题

我默认是utf8,而系统的cmd窗口编码是gbk

‍

==临时==

修改mysql客户端编码, 只针对当前窗口有效

```sql
show variables like 'character%'; 查看所有mysql的编码

在图中与客户端有关的编码设置:

client connetion result 和客户端相关

database server system 和服务器端相关

将客户端编码修改为gbk.

set character_set_results=gbk; / set names gbk;
```

‍

==永久==

修改mysql安装目录下的my.ini文件, 永久有效<sup>（修改完成配置文件，重启服务）</sup>

```sql
default-character-set=gbk 客户端编码设置

character-set-server=utf8 服务器端编码设置
```
